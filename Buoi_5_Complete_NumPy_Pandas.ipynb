{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## BU·ªîI 5: NUMPY V√Ä PANDAS\n"
      ],
      "metadata": {
        "id": "title_header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## I. NumPy\n",
        "\n",
        "NumPy l√† th∆∞ vi·ªán c∆° b·∫£n cho t√≠nh to√°n khoa h·ªçc trong Python:\n",
        "- **M·∫£ng ƒëa chi·ªÅu** hi·ªáu su·∫•t cao (ndarray)\n",
        "- **C√°c h√†m to√°n h·ªçc** ƒë·ªÉ thao t√°c v·ªõi m·∫£ng  \n",
        "- **C√¥ng c·ª•** cho ƒë·∫°i s·ªë tuy·∫øn t√≠nh, bi·∫øn ƒë·ªïi Fourier\n",
        "- **Broadcasting** v√† vectorization"
      ],
      "metadata": {
        "id": "numpy_intro_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0. T·∫°i sao n√™n d√πng c√°c th∆∞ vi·ªán nh∆∞ Numpy\n",
        "import numpy as np\n",
        "import time\n",
        "import sys\n",
        "\n",
        "size = 1000000\n",
        "python_list = list(range(size))\n",
        "numpy_array = np.arange(size)\n",
        "start_time = time.time()\n",
        "sum_list = sum(python_list)\n",
        "list_time = time.time() - start_time\n",
        "\n",
        "start_time = time.time()\n",
        "sum_numpy = np.sum(numpy_array)\n",
        "numpy_time = time.time() - start_time\n",
        "\n",
        "print(f\"Python List: {list_time:.6f}s\")\n",
        "print(f\"NumPy Array: {numpy_time:.6f}s\")\n",
        "print(f\"NumPy nhanh h∆°n: {list_time/numpy_time:.1f} l·∫ßn\")\n",
        "\n"
      ],
      "metadata": {
        "id": "numpy_performance_test",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c026c9a8-1a10-4013-a56e-65cc88465bc3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python List: 0.022285s\n",
            "NumPy Array: 0.001230s\n",
            "NumPy nhanh h∆°n: 18.1 l·∫ßn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. C√†i ƒë·∫∑t v√† import\n",
        "import numpy as np\n",
        "print(np.__version__)"
      ],
      "metadata": {
        "id": "numpy_install",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b7353a7-cbc3-45f0-9e64-5bb85368f2c0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A. T·∫°o M·∫£ng/Ma tr·∫≠n v·ªõi NumPy"
      ],
      "metadata": {
        "id": "array_creation_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#t·∫°o m·∫£ng c∆° b·∫£n\n",
        "#1d\n",
        "arr = np.array([1, 2, 3, 4, 5])\n",
        "print(arr)\n",
        "print(type(arr))"
      ],
      "metadata": {
        "id": "basic_array_creation",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39e0d63e-5fbb-4a4e-9f57-559268c1646d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 3 4 5]\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2d\n",
        "arr = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "print(arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xnJnMkAHcRd",
        "outputId": "9708afce-7102-4648-e932-e6e7c139073f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 2 3]\n",
            " [4 5 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tuple\n",
        "arr = np.array((7, 8, 9))\n",
        "print(arr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e5CIVzzH7dF",
        "outputId": "efab6cfa-008a-4134-8b5e-7b1386932029"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7 8 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ki·ªÉu c·ªßa m·∫£ng - auto detection\n",
        "arr = np.array([1.1, 2, 3, 4, 5])\n",
        "print(arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQ1J3cVmH_XW",
        "outputId": "d07c8783-7186-4cd3-e8e0-492caa05ad17"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.1 2.  3.  4.  5. ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "B. C√°c thu·ªôc t√≠nh c·ªßa M·∫£ng"
      ],
      "metadata": {
        "id": "4zTm8dVtLaco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#thu·ªôc t√≠nh c∆° b·∫£n c·ªßa m·∫£ng\n",
        "arr = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "print(arr)"
      ],
      "metadata": {
        "id": "array_attributes",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2d3208f-0829-4d95-81dc-c7bac0d43418"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 2 3]\n",
            " [4 5 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#k√≠ch th∆∞·ªõc\n",
        "print(arr.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ay7Vucm3KNH6",
        "outputId": "64da185a-471b-4a6b-a006-b728c21729cb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #s·ªë chi·ªÅu\n",
        "print(arr.ndim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "810rEahVKLrr",
        "outputId": "693f8a84-a506-4cc8-c280-cef41d41b46a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#t·ªïng s·ªë ph·∫ßn t·ª≠\n",
        "print(arr.size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOC4jWdLKyl-",
        "outputId": "ced54d20-67d7-49a9-a3a5-fd9f42a71d9c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ki·ªÉu d·ªØ li·ªáu\n",
        "print(arr.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fGXCfZ5K3av",
        "outputId": "93534420-b3ae-4ea3-c065-de1ed27aa37b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "C. C√°c h√†m t·∫°o M·∫£ng"
      ],
      "metadata": {
        "id": "eBVkIf5iL12p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Empty\n",
        "empty_arr = np.empty((3, 3))\n",
        "print(empty_arr)"
      ],
      "metadata": {
        "id": "special_array_functions",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1db04301-8fe7-4ce2-937d-098f4112b60e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ma tr·∫≠n ƒë∆°n v·ªã\n",
        "eye_arr = np.eye(4, 6)\n",
        "print(eye_arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-F9GaTPMqR9",
        "outputId": "9b3346b2-8db8-4514-c240-a90a243afe3f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "identity_arr = np.identity(4)\n",
        "print(identity_arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DngE8_7pMsWV",
        "outputId": "420f4b53-be98-4d9a-d9ee-99ccaad57358"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ma tr·∫≠n 0\n",
        "zeros_arr = np.zeros((3, 3))\n",
        "print(zeros_arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gorEM9oMvI7",
        "outputId": "5b42b544-13f9-45da-e797-f2aabc00ff79"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ones_arr = np.ones((5, 7))\n",
        "print(ones_arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ-sv01qMzhe",
        "outputId": "ea3e7ffa-2b95-4018-a25c-852ea2b32ab0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# T·∫°o d√£y s·ªë v·ªõi arange: np.arange(start, stop, step, dtype)\n",
        "arr1 = np.arange(5)\n",
        "print(arr1)"
      ],
      "metadata": {
        "id": "arange_linspace",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84df1ce0-1f28-4f6d-db07-2936f5065a2a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 3 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr2 = np.arange(2, 8)\n",
        "print(arr2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6vvtIEwNJWc",
        "outputId": "dc74a559-e77f-4dac-aaee-893fcb2a25d6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 3 4 5 6 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr3 = np.arange(0, 10, 2)\n",
        "print(arr3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzIspHYwNMj0",
        "outputId": "fcb337f4-8719-4bd6-e790-0e7528a3c774"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 2 4 6 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr4 = np.arange(10, 0, -1)\n",
        "print(arr4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dka1wOsHNOts",
        "outputId": "fc4454cd-6476-4948-e976-d638b288175b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10  9  8  7  6  5  4  3  2  1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# T·∫°o m·∫£ng ng·∫´u nhi√™n\n",
        "# np.random.seed(2210)\n",
        "\n",
        "# Random [0, 1)\n",
        "random_arr = np.random.random((3, 3))\n",
        "print(random_arr)"
      ],
      "metadata": {
        "id": "random_arrays",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebc60067-a3e3-4ea1-8e90-f253b045344a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.60233155 0.42211725 0.43571595]\n",
            " [0.80995802 0.3814851  0.20479196]\n",
            " [0.89715092 0.91423299 0.73233411]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random integers\n",
        "arr = np.random.randint(1, 100, (3, 3))\n",
        "print(arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNQIxggGNxak",
        "outputId": "85a62db8-73a1-4cbc-d9e0-e73dab3f9d80"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[77 30 34]\n",
            " [ 1 51 57]\n",
            " [93 99 37]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean = np.mean(arr)           # Trung b√¨nh\n",
        "median = np.median(arr)       # Trung v·ªã\n",
        "std = np.std(arr)            # ƒê·ªô l·ªách chu·∫©n\n",
        "var = np.var(arr)            # Ph∆∞∆°ng sai\n",
        "min_val = np.min(arr)        # Gi√° tr·ªã nh·ªè nh·∫•t\n",
        "max_val = np.max(arr)        # Gi√° tr·ªã l·ªõn nh·∫•t\n",
        "\n",
        "print(mean)\n",
        "print(median)\n",
        "print(std)\n",
        "print(var)\n",
        "print(min_val)\n",
        "print(max_val)"
      ],
      "metadata": {
        "id": "ShWS51GyS-7_",
        "outputId": "f339a645-d501-4743-df60-760ff388f42d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "106.70681128985426\n",
            "106.99034747506649\n",
            "17.140012477109035\n",
            "293.7800277154534\n",
            "85.5713939296516\n",
            "127.24638956118517\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "D. Indexing v√† Slicing"
      ],
      "metadata": {
        "id": "indexing_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.random.randint(0, 10, (5))\n",
        "arr2 = np.random.randint(0, 10, (3, 5))\n",
        "arr3 = np.random.randint(0, 10, (3, 3, 3))\n",
        "\n",
        "print(arr)\n",
        "print(arr2)\n",
        "print(arr3)"
      ],
      "metadata": {
        "id": "indexing_1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52df6f4a-2ecc-41c3-bcff-bf53e6aba020"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 7 8 8 1]\n",
            "[[1 3 8 0 8]\n",
            " [2 1 3 5 3]\n",
            " [7 4 7 9 3]]\n",
            "[[[3 2 9]\n",
            "  [1 0 9]\n",
            "  [2 3 2]]\n",
            "\n",
            " [[9 6 0]\n",
            "  [4 1 4]\n",
            "  [6 5 8]]\n",
            "\n",
            " [[3 0 4]\n",
            "  [2 4 1]\n",
            "  [3 2 6]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1d\n",
        "print(arr[0])\n",
        "print(arr[3])\n",
        "print(arr[-1])\n",
        "print(arr[-4])\n",
        "\n",
        "print(arr[1:4])\n",
        "print(arr[:3])\n",
        "print(arr[2:])\n",
        "print(arr[::2])\n",
        "print(arr[::-1])"
      ],
      "metadata": {
        "id": "l3UFK-jfffEz",
        "outputId": "429a4cab-6bee-41dc-fca2-3db47ebd728e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "8\n",
            "1\n",
            "7\n",
            "[7 8 8]\n",
            "[2 7 8]\n",
            "[8 8 1]\n",
            "[2 8 1]\n",
            "[1 8 8 7 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2d\n",
        "print(arr2)\n",
        "\n",
        "print(arr2[0, 0])\n",
        "print(arr2[1, 2])\n",
        "print(arr2[-1, -1])\n",
        "print(arr2[2, 1])\n",
        "\n",
        "print(arr2[0, :])\n",
        "print(arr2[:, 0])\n",
        "print(arr2[-1, :])\n",
        "print(arr2[:, -1])\n",
        "\n",
        "print(arr2[:2, :])\n",
        "print(arr2[:, -2:])\n",
        "print(arr2[1:, 1:4])"
      ],
      "metadata": {
        "id": "indexing_2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb522034-a0bc-4a0b-dbe8-618470af491f"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 3 8 0 8]\n",
            " [2 1 3 5 3]\n",
            " [7 4 7 9 3]]\n",
            "1\n",
            "3\n",
            "3\n",
            "4\n",
            "[1 3 8 0 8]\n",
            "[1 2 7]\n",
            "[7 4 7 9 3]\n",
            "[8 3 3]\n",
            "[[1 3 8 0 8]\n",
            " [2 1 3 5 3]]\n",
            "[[0 8]\n",
            " [5 3]\n",
            " [9 3]]\n",
            "[[1 3 5]\n",
            " [4 7 9]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "E. Bi·∫øn ƒë·ªïi m·∫£ng"
      ],
      "metadata": {
        "id": "array_transformation_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape\n",
        "arr = np.arange(1, 25)\n",
        "print(arr)\n",
        "print(arr)"
      ],
      "metadata": {
        "id": "reshape_operations",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db8eacac-9720-449d-b3c0-f253a9855ece"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n",
            "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(arr.reshape(2, 12))"
      ],
      "metadata": {
        "id": "9-vdQghWiNH2",
        "outputId": "274f1c98-4f7b-462a-ee4d-8c73067dcccd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
            " [13 14 15 16 17 18 19 20 21 22 23 24]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(arr.reshape(3, 8))"
      ],
      "metadata": {
        "id": "LXMnCbKJiROi",
        "outputId": "ad785181-9d70-4059-c2c9-c3d3c5c6928d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  2  3  4  5  6  7  8]\n",
            " [ 9 10 11 12 13 14 15 16]\n",
            " [17 18 19 20 21 22 23 24]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(arr.reshape(4, 6))"
      ],
      "metadata": {
        "id": "9TBXTDhfiSU-",
        "outputId": "958dca71-1922-4748-db09-c393aa1fd252",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  2  3  4  5  6]\n",
            " [ 7  8  9 10 11 12]\n",
            " [13 14 15 16 17 18]\n",
            " [19 20 21 22 23 24]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(arr.reshape(4, 3, 2))"
      ],
      "metadata": {
        "id": "t9F6syP4iTLD",
        "outputId": "0dc21602-d7f1-4381-a9f2-2e0bb07c1c88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 1  2]\n",
            "  [ 3  4]\n",
            "  [ 5  6]]\n",
            "\n",
            " [[ 7  8]\n",
            "  [ 9 10]\n",
            "  [11 12]]\n",
            "\n",
            " [[13 14]\n",
            "  [15 16]\n",
            "  [17 18]]\n",
            "\n",
            " [[19 20]\n",
            "  [21 22]\n",
            "  [23 24]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Auto reshape v·ªõi -1\n",
        "auto1 = arr.reshape(-1, 6)\n",
        "auto2 = arr.reshape(3, -1)\n",
        "print(auto1.shape)\n",
        "print(auto2.shape)"
      ],
      "metadata": {
        "id": "RInQ5FCxiPgG",
        "outputId": "c95affd7-3fe0-489c-8e47-9d1af36558d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 6)\n",
            "(3, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transpose\n",
        "matrix = np.arange(1, 13).reshape(3, 4)\n",
        "print(matrix)\n",
        "print()\n",
        "# print(matrix.T)\n",
        "print(matrix.transpose())\n",
        "print()\n",
        "print(matrix)\n"
      ],
      "metadata": {
        "id": "transpose_flatten",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c8a38eb-05e8-4e03-a1a4-f511520b461f"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  2  3  4]\n",
            " [ 5  6  7  8]\n",
            " [ 9 10 11 12]]\n",
            "\n",
            "[[ 1  5  9]\n",
            " [ 2  6 10]\n",
            " [ 3  7 11]\n",
            " [ 4  8 12]]\n",
            "\n",
            "[[ 1  2  3  4]\n",
            " [ 5  6  7  8]\n",
            " [ 9 10 11 12]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "F. C√°c ph√©p to√°n v√† h√†m to√°n h·ªçc"
      ],
      "metadata": {
        "id": "math_operations_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "a = np.array([1, 2, 3, 4])\n",
        "b = np.array([5, 6, 7, 8])\n",
        "\n",
        "print(f\"a = {a}\")\n",
        "print(f\"b = {b}\")\n",
        "print(f\"a + b = {a + b}\")\n",
        "print(f\"a - b = {a - b}\")\n",
        "print(f\"a * b = {a * b}\")\n",
        "print(f\"a / b = {a / b}\")\n",
        "print(f\"a ** 2 = {a ** 2}\")\n",
        "print(f\"a % 3 = {a % 3}\")"
      ],
      "metadata": {
        "id": "basic_math_operations",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "235920f8-03f9-47ff-82b8-893116ffcb52"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a = [1 2 3 4]\n",
            "b = [5 6 7 8]\n",
            "a + b = [ 6  8 10 12]\n",
            "a - b = [-4 -4 -4 -4]\n",
            "a * b = [ 5 12 21 32]\n",
            "a / b = [0.2        0.33333333 0.42857143 0.5       ]\n",
            "a ** 2 = [ 1  4  9 16]\n",
            "a % 3 = [1 2 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#broadcasting\n",
        "matrix = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "vector = np.array([10, 20, 30])\n",
        "scalar = 100\n",
        "\n",
        "print(matrix)\n",
        "print(vector)\n",
        "print(scalar)\n",
        "\n",
        "print(matrix + vector)\n",
        "print(matrix + scalar)\n",
        "print(matrix * vector)"
      ],
      "metadata": {
        "id": "ZnNN9g_ZowRh",
        "outputId": "9e690c0d-dfb8-4e9e-ab0d-abebf39a19da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 2 3]\n",
            " [4 5 6]]\n",
            "[10 20 30]\n",
            "100\n",
            "[[11 22 33]\n",
            " [14 25 36]]\n",
            "[[101 102 103]\n",
            " [104 105 106]]\n",
            "[[ 10  40  90]\n",
            " [ 40 100 180]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mathematical functions\n",
        "arr = np.array([1, 4, 9, 16, 25])\n",
        "print(arr)"
      ],
      "metadata": {
        "id": "advanced_math_functions",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "426c29ce-ecb0-4ce6-b54a-76483fe48de4"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1  4  9 16 25]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.sqrt(arr))\n",
        "print(np.square(arr))\n",
        "print(np.abs(arr))"
      ],
      "metadata": {
        "id": "TZlzq02lp7Tq",
        "outputId": "088fbfc9-3335-4a96-a443-208ea56c87fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 2. 3. 4. 5.]\n",
            "[  1  16  81 256 625]\n",
            "[ 1  4  9 16 25]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#statistical functions\n",
        "data = np.random.normal(50, 10, 100)\n",
        "print(data[:10])\n",
        "\n",
        "print(f\"Mean: {np.mean(data):.2f}\")\n",
        "print(f\"Median: {np.median(data):.2f}\")\n",
        "print(f\"Std: {np.std(data):.2f}\")\n",
        "print(f\"Var: {np.var(data):.2f}\")\n",
        "print(f\"Min: {np.min(data):.2f}\")\n",
        "print(f\"Max: {np.max(data):.2f}\")\n",
        "print(f\"Sum: {np.sum(data):.2f}\")"
      ],
      "metadata": {
        "id": "statistical_functions",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32a2871f-dc19-4afe-c5c8-c81bfa22f580"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[62.15927421 42.62882284 27.76669075 35.80650986 48.52927984 39.78268108\n",
            " 31.62254036 55.2096101  46.14563055 50.15922024]\n",
            "Mean: 48.12\n",
            "Median: 46.86\n",
            "Std: 9.25\n",
            "Var: 85.60\n",
            "Min: 27.77\n",
            "Max: 72.55\n",
            "Sum: 4811.71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "II. Pandas\n",
        "\n",
        "Pandas cung c·∫•p c·∫•u tr√∫c d·ªØ li·ªáu v√† c√¥ng c·ª• ph√¢n t√≠ch d·ªØ li·ªáu m·∫°nh m·∫Ω:\n",
        "- **Series**: m·∫£ng 1 chi·ªÅu c√≥ nh√£n\n",
        "- **DataFrame**: b·∫£ng d·ªØ li·ªáu 2 chi·ªÅu\n",
        "- **C√¥ng c·ª•**: x·ª≠ l√Ω d·ªØ li·ªáu thi·∫øu, merge, group by"
      ],
      "metadata": {
        "id": "pandas_section_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Pandas\n",
        "import pandas as pd\n",
        "print(pd.__version__)\n"
      ],
      "metadata": {
        "id": "pandas_import",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "000dccce-c751-4858-ae44-5e71cc6a2b4a"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A. Pandas Series"
      ],
      "metadata": {
        "id": "pandas_series_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Pandas Series\n",
        "\n",
        "print(\"üî∏ T·∫°o Series:\")\n",
        "s1 = pd.Series([1, 3, 5, 7, 9])\n",
        "print(s1)\n",
        "\n",
        "s2 = pd.Series([100, 200, 300], index=['A', 'B', 'C'])\n",
        "print(f\"\\nSeries v·ªõi custom index:\\n{s2}\")\n",
        "\n",
        "# Series t·ª´ dictionary\n",
        "data_dict = {'Apple': 150, 'Banana': 80, 'Orange': 120, 'Mango': 200}\n",
        "s3 = pd.Series(data_dict)\n",
        "print(f\"\\nSeries t·ª´ dictionary:\\n{s3}\")\n",
        "\n",
        "# Series t·ª´ numpy array\n",
        "np_arr = np.random.randint(50, 100, 5)\n",
        "s4 = pd.Series(np_arr, index=['Mon', 'Tue', 'Wed', 'Thu', 'Fri'])\n",
        "print(f\"\\nSeries t·ª´ numpy (ƒëi·ªÉm s·ªë tu·∫ßn):\\n{s4}\")\n",
        "\n",
        "print(f\"\\nüî∏ Thu·ªôc t√≠nh Series:\")\n",
        "print(f\"Values: {s3.values}\")\n",
        "print(f\"Index: {s3.index.tolist()}\")\n",
        "print(f\"Data type: {s3.dtype}\")\n",
        "print(f\"Size: {s3.size}\")\n",
        "print(f\"Shape: {s3.shape}\")"
      ],
      "metadata": {
        "id": "pandas_series_creation"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Truy xu·∫•t d·ªØ li·ªáu Series\n",
        "print(\"üî∏ Truy xu·∫•t d·ªØ li·ªáu Series:\")\n",
        "print(f\"Series: {s3}\")\n",
        "\n",
        "# Label-based indexing\n",
        "print(f\"\\nLabel-based indexing:\")\n",
        "print(f\"s3['Apple'] = {s3['Apple']}\")\n",
        "print(f\"s3[['Apple', 'Mango']] = \\n{s3[['Apple', 'Mango']]}\")\n",
        "\n",
        "# Position-based indexing\n",
        "print(f\"\\nPosition-based indexing:\")\n",
        "print(f\"s3.iloc[0] = {s3.iloc[0]}\")\n",
        "print(f\"s3.iloc[1:3] = \\n{s3.iloc[1:3]}\")\n",
        "\n",
        "# Boolean indexing\n",
        "print(f\"\\nBoolean indexing:\")\n",
        "expensive = s3 > 100\n",
        "print(f\"Expensive fruits (>100): \\n{s3[expensive]}\")\n",
        "\n",
        "# Operations on Series\n",
        "print(f\"\\nüî∏ Operations on Series:\")\n",
        "print(f\"Original prices:\\n{s3}\")\n",
        "print(f\"\\nPrice * 1.1 (10% increase):\\n{s3 * 1.1}\")\n",
        "print(f\"\\nPrice + 20 (add 20):\\n{s3 + 20}\")\n",
        "print(f\"\\nMath operations:\")\n",
        "print(f\"Sum: {s3.sum()}\")\n",
        "print(f\"Mean: {s3.mean():.2f}\")\n",
        "print(f\"Max: {s3.max()}\")\n",
        "print(f\"Min: {s3.min()}\")\n",
        "print(f\"Std: {s3.std():.2f}\")"
      ],
      "metadata": {
        "id": "series_operations"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## II. Pandas DataFrame"
      ],
      "metadata": {
        "id": "dataframe_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Pandas DataFrame\n",
        "print(\"üìã 2. PANDAS DATAFRAME\")\n",
        "print(\"=\" * 35)\n",
        "\n",
        "# T·∫°o DataFrame t·ª´ dictionary\n",
        "print(\"üî∏ T·∫°o DataFrame t·ª´ dictionary:\")\n",
        "data = {\n",
        "    'T√™n': ['An', 'B√¨nh', 'Chi', 'Dung', 'Em', 'Phong'],\n",
        "    'Tu·ªïi': [25, 30, 35, 28, 22, 27],\n",
        "    'L∆∞∆°ng': [5000, 6000, 7000, 5500, 4500, 5800],\n",
        "    'Th√†nh ph·ªë': ['H√† N·ªôi', 'HCM', 'ƒê√† N·∫µng', 'H√† N·ªôi', 'HCM', 'C·∫ßn Th∆°'],\n",
        "    'Kinh nghi·ªám': [2, 5, 8, 4, 1, 3]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(\"DataFrame nh√¢n vi√™n:\")\n",
        "print(df)\n",
        "\n",
        "# T·∫°o DataFrame t·ª´ list of lists\n",
        "print(f\"\\nüî∏ DataFrame t·ª´ list of lists:\")\n",
        "data_list = [\n",
        "    ['Product A', 100, 'Electronics'],\n",
        "    ['Product B', 150, 'Clothing'],\n",
        "    ['Product C', 80, 'Books'],\n",
        "    ['Product D', 200, 'Electronics']\n",
        "]\n",
        "df_products = pd.DataFrame(data_list, columns=['Product', 'Price', 'Category'])\n",
        "print(\"DataFrame s·∫£n ph·∫©m:\")\n",
        "print(df_products)\n",
        "\n",
        "# Th√¥ng tin c∆° b·∫£n v·ªÅ DataFrame\n",
        "print(f\"\\nüî∏ Th√¥ng tin c∆° b·∫£n v·ªÅ DataFrame:\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n",
        "print(f\"Index: {list(df.index)}\")\n",
        "print(f\"Size: {df.size}\")\n",
        "print(f\"\\nData types:\\n{df.dtypes}\")"
      ],
      "metadata": {
        "id": "dataframe_creation"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Xem v√† kh√°m ph√° d·ªØ li·ªáu\n",
        "print(\"üî∏ Xem v√† kh√°m ph√° d·ªØ li·ªáu:\")\n",
        "\n",
        "print(\"Head (3 d√≤ng ƒë·∫ßu):\")\n",
        "print(df.head(3))\n",
        "\n",
        "print(\"\\nTail (3 d√≤ng cu·ªëi):\")\n",
        "print(df.tail(3))\n",
        "\n",
        "print(\"\\nInfo (th√¥ng tin t·ªïng quan):\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\nDescribe (th·ªëng k√™ m√¥ t·∫£ cho c·ªôt s·ªë):\")\n",
        "print(df.describe())\n",
        "\n",
        "print(\"\\nDescribe cho t·∫•t c·∫£ c·ªôt:\")\n",
        "print(df.describe(include='all'))"
      ],
      "metadata": {
        "id": "dataframe_exploration"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Truy xu·∫•t d·ªØ li·ªáu DataFrame\n",
        "print(\"üî∏ Truy xu·∫•t d·ªØ li·ªáu DataFrame:\")\n",
        "\n",
        "# Truy xu·∫•t c·ªôt\n",
        "print(\"Truy xu·∫•t c·ªôt 'T√™n':\")\n",
        "print(df['T√™n'])\n",
        "print(f\"Type: {type(df['T√™n'])}\")\n",
        "\n",
        "print(\"\\nTruy xu·∫•t nhi·ªÅu c·ªôt:\")\n",
        "print(df[['T√™n', 'L∆∞∆°ng', 'Th√†nh ph·ªë']])\n",
        "\n",
        "# Truy xu·∫•t h√†ng\n",
        "print(\"\\nüî∏ Truy xu·∫•t h√†ng:\")\n",
        "print(\"H√†ng ƒë·∫ßu ti√™n (iloc - position):\")\n",
        "print(df.iloc[0])\n",
        "\n",
        "print(\"\\nH√†ng ƒë·∫ßu ti√™n (loc - label):\")\n",
        "print(df.loc[0])\n",
        "\n",
        "print(\"\\nNhi·ªÅu h√†ng (iloc):\")\n",
        "print(df.iloc[1:4])\n",
        "\n",
        "print(\"\\nNhi·ªÅu h√†ng (loc):\")\n",
        "print(df.loc[1:3])  # Inclusive end v·ªõi loc\n",
        "\n",
        "# Truy xu·∫•t √¥ c·ª• th·ªÉ\n",
        "print(f\"\\nüî∏ Truy xu·∫•t √¥ c·ª• th·ªÉ:\")\n",
        "print(f\"df.iloc[0, 1] (h√†ng 0, c·ªôt 1): {df.iloc[0, 1]}\")\n",
        "print(f\"df.loc[0, 'Tu·ªïi'] (h√†ng 0, c·ªôt 'Tu·ªïi'): {df.loc[0, 'Tu·ªïi']}\")\n",
        "print(f\"df.at[0, 'T√™n'] (nhanh nh·∫•t cho 1 √¥): {df.at[0, 'T√™n']}\")\n",
        "\n",
        "# Truy xu·∫•t v·ªõi ƒëi·ªÅu ki·ªán\n",
        "print(f\"\\nüî∏ Slice v·ªõi ƒëi·ªÅu ki·ªán:\")\n",
        "print(\"L·∫•y t√™n v√† l∆∞∆°ng c·ªßa 3 ng∆∞·ªùi ƒë·∫ßu:\")\n",
        "print(df.loc[0:2, ['T√™n', 'L∆∞∆°ng']])"
      ],
      "metadata": {
        "id": "dataframe_access"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## III. L·ªçc v√† t√¨m ki·∫øm d·ªØ li·ªáu"
      ],
      "metadata": {
        "id": "filtering_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. L·ªçc v√† t√¨m ki·∫øm d·ªØ li·ªáu\n",
        "print(\"üîç 3. L·ªåC V√Ä T√åM KI·∫æM D·ªÆ LI·ªÜU\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "print(\"DataFrame g·ªëc:\")\n",
        "print(df)\n",
        "\n",
        "# L·ªçc theo ƒëi·ªÅu ki·ªán ƒë∆°n\n",
        "print(\"\\nüî∏ L·ªçc theo ƒëi·ªÅu ki·ªán ƒë∆°n:\")\n",
        "high_salary = df[df['L∆∞∆°ng'] > 5500]\n",
        "print(\"Ng∆∞·ªùi c√≥ l∆∞∆°ng > 5500:\")\n",
        "print(high_salary)\n",
        "\n",
        "young_people = df[df['Tu·ªïi'] < 30]\n",
        "print(\"\\nNg∆∞·ªùi tr·∫ª (<30 tu·ªïi):\")\n",
        "print(young_people[['T√™n', 'Tu·ªïi', 'L∆∞∆°ng']])\n",
        "\n",
        "# L·ªçc theo nhi·ªÅu ƒëi·ªÅu ki·ªán\n",
        "print(\"\\nüî∏ L·ªçc theo nhi·ªÅu ƒëi·ªÅu ki·ªán:\")\n",
        "young_high_salary = df[(df['Tu·ªïi'] < 30) & (df['L∆∞∆°ng'] > 5000)]\n",
        "print(\"Tu·ªïi < 30 V√Ä l∆∞∆°ng > 5000:\")\n",
        "print(young_high_salary[['T√™n', 'Tu·ªïi', 'L∆∞∆°ng']])\n",
        "\n",
        "experienced_or_young = df[(df['Kinh nghi·ªám'] >= 5) | (df['Tu·ªïi'] <= 25)]\n",
        "print(\"\\nKinh nghi·ªám ‚â• 5 HO·∫∂C tu·ªïi ‚â§ 25:\")\n",
        "print(experienced_or_young[['T√™n', 'Tu·ªïi', 'Kinh nghi·ªám']])\n",
        "\n",
        "# L·ªçc theo string\n",
        "print(\"\\nüî∏ L·ªçc theo string:\")\n",
        "hanoi_people = df[df['Th√†nh ph·ªë'] == 'H√† N·ªôi']\n",
        "print(\"Ng∆∞·ªùi ·ªü H√† N·ªôi:\")\n",
        "print(hanoi_people[['T√™n', 'Th√†nh ph·ªë', 'L∆∞∆°ng']])\n",
        "\n",
        "# Contains string\n",
        "name_with_n = df[df['T√™n'].str.contains('n', case=False)]\n",
        "print(\"\\nT√™n ch·ª©a ch·ªØ 'n':\")\n",
        "print(name_with_n[['T√™n']])"
      ],
      "metadata": {
        "id": "basic_filtering"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# L·ªçc n√¢ng cao\n",
        "print(\"üî∏ L·ªçc n√¢ng cao:\")\n",
        "\n",
        "# L·ªçc theo danh s√°ch\n",
        "selected_cities = df[df['Th√†nh ph·ªë'].isin(['H√† N·ªôi', 'HCM'])]\n",
        "print(\"Ng∆∞·ªùi ·ªü H√† N·ªôi ho·∫∑c HCM:\")\n",
        "print(selected_cities[['T√™n', 'Th√†nh ph·ªë']])\n",
        "\n",
        "# L·ªçc theo range\n",
        "mid_range_salary = df[df['L∆∞∆°ng'].between(5000, 6000)]\n",
        "print(\"\\nL∆∞∆°ng t·ª´ 5000-6000:\")\n",
        "print(mid_range_salary[['T√™n', 'L∆∞∆°ng']])\n",
        "\n",
        "# Query method (SQL-like)\n",
        "print(\"\\nüî∏ S·ª≠ d·ª•ng query() method:\")\n",
        "result1 = df.query('Tu·ªïi >= 28 and L∆∞∆°ng <= 6000')\n",
        "print(\"Query: 'Tu·ªïi >= 28 and L∆∞∆°ng <= 6000'\")\n",
        "print(result1[['T√™n', 'Tu·ªïi', 'L∆∞∆°ng']])\n",
        "\n",
        "result2 = df.query('Th√†nh_ph·ªë == \"H√† N·ªôi\" and Kinh_nghi·ªám > 2')\n",
        "print(\"\\nQuery: 'Th√†nh_ph·ªë == \"H√† N·ªôi\" and Kinh_nghi·ªám > 2'\")\n",
        "print(result2[['T√™n', 'Th√†nh ph·ªë', 'Kinh nghi·ªám']])\n",
        "\n",
        "# Negate conditions\n",
        "print(\"\\nüî∏ ƒêi·ªÅu ki·ªán ph·ªß ƒë·ªãnh:\")\n",
        "not_hanoi = df[~(df['Th√†nh ph·ªë'] == 'H√† N·ªôi')]\n",
        "print(\"Kh√¥ng ·ªü H√† N·ªôi:\")\n",
        "print(not_hanoi[['T√™n', 'Th√†nh ph·ªë']])\n",
        "\n",
        "# Top/Bottom records\n",
        "print(\"\\nüî∏ Top/Bottom records:\")\n",
        "top_salary = df.nlargest(3, 'L∆∞∆°ng')\n",
        "print(\"Top 3 l∆∞∆°ng cao nh·∫•t:\")\n",
        "print(top_salary[['T√™n', 'L∆∞∆°ng']])\n",
        "\n",
        "youngest = df.nsmallest(2, 'Tu·ªïi')\n",
        "print(\"\\n2 ng∆∞·ªùi tr·∫ª nh·∫•t:\")\n",
        "print(youngest[['T√™n', 'Tu·ªïi']])"
      ],
      "metadata": {
        "id": "advanced_filtering"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IV. Th√™m, s·ª≠a, x√≥a d·ªØ li·ªáu"
      ],
      "metadata": {
        "id": "data_manipulation_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Th√™m, s·ª≠a, x√≥a d·ªØ li·ªáu\n",
        "print(\"‚ûï 4. TH√äM, S·ª¨A, X√ìA D·ªÆ LI·ªÜU\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# T·∫°o copy ƒë·ªÉ kh√¥ng ·∫£nh h∆∞·ªüng df g·ªëc\n",
        "df_work = df.copy()\n",
        "\n",
        "# Th√™m c·ªôt m·ªõi\n",
        "print(\"üî∏ Th√™m c·ªôt m·ªõi:\")\n",
        "print(\"DataFrame g·ªëc:\")\n",
        "print(df_work[['T√™n', 'L∆∞∆°ng']])\n",
        "\n",
        "# Th√™m c·ªôt t√≠nh to√°n\n",
        "df_work['Th∆∞·ªüng'] = df_work['L∆∞∆°ng'] * 0.1\n",
        "df_work['T·ªïng_thu_nh·∫≠p'] = df_work['L∆∞∆°ng'] + df_work['Th∆∞·ªüng']\n",
        "\n",
        "# Th√™m c·ªôt ƒëi·ªÅu ki·ªán\n",
        "df_work['C·∫•p_ƒë·ªô'] = df_work['Tu·ªïi'].apply(lambda x: 'Senior' if x >= 30 else 'Junior')\n",
        "\n",
        "# Th√™m c·ªôt v·ªõi multiple conditions\n",
        "def classify_employee(row):\n",
        "    if row['Kinh nghi·ªám'] >= 5:\n",
        "        return 'Expert'\n",
        "    elif row['Kinh nghi·ªám'] >= 3:\n",
        "        return 'Experienced'\n",
        "    else:\n",
        "        return 'Beginner'\n",
        "\n",
        "df_work['Ph√¢n_lo·∫°i'] = df_work.apply(classify_employee, axis=1)\n",
        "\n",
        "print(\"\\nSau khi th√™m c·ªôt:\")\n",
        "print(df_work[['T√™n', 'L∆∞∆°ng', 'Th∆∞·ªüng', 'T·ªïng_thu_nh·∫≠p', 'C·∫•p_ƒë·ªô', 'Ph√¢n_lo·∫°i']])\n",
        "\n",
        "# Th√™m h√†ng m·ªõi\n",
        "print(\"\\nüî∏ Th√™m h√†ng m·ªõi:\")\n",
        "new_employees = [\n",
        "    {'T√™n': 'Giang', 'Tu·ªïi': 26, 'L∆∞∆°ng': 5200, 'Th√†nh ph·ªë': 'H√† N·ªôi', 'Kinh nghi·ªám': 2},\n",
        "    {'T√™n': 'Ho√†ng', 'Tu·ªïi': 32, 'L∆∞∆°ng': 6500, 'Th√†nh ph·ªë': 'HCM', 'Kinh nghi·ªám': 6}\n",
        "]\n",
        "\n",
        "df_new = pd.concat([df, pd.DataFrame(new_employees)], ignore_index=True)\n",
        "print(\"DataFrame sau khi th√™m 2 nh√¢n vi√™n m·ªõi:\")\n",
        "print(df_new.tail(4))  # Show last 4 rows"
      ],
      "metadata": {
        "id": "add_columns_rows"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# S·ª≠a d·ªØ li·ªáu\n",
        "print(\"üî∏ S·ª≠a d·ªØ li·ªáu:\")\n",
        "df_edit = df.copy()\n",
        "\n",
        "print(\"Tr∆∞·ªõc khi s·ª≠a:\")\n",
        "print(df_edit.loc[0, ['T√™n', 'L∆∞∆°ng']])\n",
        "\n",
        "# S·ª≠a 1 √¥\n",
        "df_edit.loc[0, 'L∆∞∆°ng'] = 5200\n",
        "print(f\"\\nSau khi s·ª≠a l∆∞∆°ng An th√†nh 5200:\")\n",
        "print(df_edit.loc[0, ['T√™n', 'L∆∞∆°ng']])\n",
        "\n",
        "# S·ª≠a nhi·ªÅu √¥\n",
        "df_edit.loc[df_edit['T√™n'] == 'B√¨nh', ['L∆∞∆°ng', 'Tu·ªïi']] = [6200, 31]\n",
        "print(f\"\\nSau khi s·ª≠a th√¥ng tin B√¨nh:\")\n",
        "print(df_edit[df_edit['T√™n'] == 'B√¨nh'][['T√™n', 'Tu·ªïi', 'L∆∞∆°ng']])\n",
        "\n",
        "# S·ª≠a c·∫£ c·ªôt\n",
        "print(f\"\\nTr∆∞·ªõc khi tƒÉng tu·ªïi:\")\n",
        "print(df_edit[['T√™n', 'Tu·ªïi']])\n",
        "\n",
        "df_edit['Tu·ªïi'] = df_edit['Tu·ªïi'] + 1  # TƒÉng tu·ªïi 1\n",
        "print(f\"\\nSau khi tƒÉng tu·ªïi to√†n b·ªô:\")\n",
        "print(df_edit[['T√™n', 'Tu·ªïi']])\n",
        "\n",
        "# S·ª≠a theo ƒëi·ªÅu ki·ªán\n",
        "print(f\"\\nTr∆∞·ªõc khi tƒÉng l∆∞∆°ng cho ng∆∞·ªùi l∆∞∆°ng th·∫•p:\")\n",
        "low_salary_before = df_edit[df_edit['L∆∞∆°ng'] < 5500][['T√™n', 'L∆∞∆°ng']]\n",
        "print(low_salary_before)\n",
        "\n",
        "df_edit.loc[df_edit['L∆∞∆°ng'] < 5500, 'L∆∞∆°ng'] *= 1.1  # TƒÉng 10%\n",
        "print(f\"\\nSau khi tƒÉng l∆∞∆°ng 10% cho ng∆∞·ªùi c√≥ l∆∞∆°ng < 5500:\")\n",
        "updated_salaries = df_edit[df_edit.index.isin(low_salary_before.index)][['T√™n', 'L∆∞∆°ng']]\n",
        "print(updated_salaries)"
      ],
      "metadata": {
        "id": "edit_data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X√≥a d·ªØ li·ªáu\n",
        "print(\"üî∏ X√≥a d·ªØ li·ªáu:\")\n",
        "df_delete = df.copy()\n",
        "\n",
        "print(\"DataFrame g·ªëc:\")\n",
        "print(df_delete.columns.tolist())\n",
        "print(f\"Shape: {df_delete.shape}\")\n",
        "\n",
        "# X√≥a c·ªôt\n",
        "df_dropped_col = df_delete.drop('Th√†nh ph·ªë', axis=1)\n",
        "print(f\"\\nSau khi x√≥a c·ªôt 'Th√†nh ph·ªë':\")\n",
        "print(df_dropped_col.columns.tolist())\n",
        "print(f\"Shape: {df_dropped_col.shape}\")\n",
        "\n",
        "# X√≥a nhi·ªÅu c·ªôt\n",
        "df_dropped_cols = df_delete.drop(['Th√†nh ph·ªë', 'Kinh nghi·ªám'], axis=1)\n",
        "print(f\"\\nSau khi x√≥a 2 c·ªôt:\")\n",
        "print(df_dropped_cols.columns.tolist())\n",
        "\n",
        "# X√≥a h√†ng\n",
        "print(f\"\\nTr∆∞·ªõc khi x√≥a h√†ng:\")\n",
        "print(df_delete[['T√™n', 'Tu·ªïi']])\n",
        "\n",
        "df_dropped_row = df_delete.drop(0, axis=0)  # X√≥a h√†ng index 0\n",
        "print(f\"\\nSau khi x√≥a h√†ng ƒë·∫ßu ti√™n (An):\")\n",
        "print(df_dropped_row[['T√™n', 'Tu·ªïi']])\n",
        "\n",
        "# X√≥a nhi·ªÅu h√†ng\n",
        "df_dropped_rows = df_delete.drop([0, 2], axis=0)  # X√≥a An v√† Chi\n",
        "print(f\"\\nSau khi x√≥a h√†ng 0 v√† 2 (An v√† Chi):\")\n",
        "print(df_dropped_rows[['T√™n', 'Tu·ªïi']])\n",
        "\n",
        "# X√≥a theo ƒëi·ªÅu ki·ªán\n",
        "df_conditional_drop = df_delete[df_delete['Tu·ªïi'] >= 25]  # Gi·ªØ l·∫°i ng∆∞·ªùi >= 25 tu·ªïi\n",
        "print(f\"\\nSau khi x√≥a ng∆∞·ªùi < 25 tu·ªïi:\")\n",
        "print(df_conditional_drop[['T√™n', 'Tu·ªïi']])\n",
        "\n",
        "# Reset index sau khi x√≥a\n",
        "df_reset = df_dropped_rows.reset_index(drop=True)\n",
        "print(f\"\\nSau khi reset index:\")\n",
        "print(df_reset[['T√™n', 'Tu·ªïi']])"
      ],
      "metadata": {
        "id": "delete_data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## V. X·ª≠ l√Ω d·ªØ li·ªáu thi·∫øu"
      ],
      "metadata": {
        "id": "missing_data_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. X·ª≠ l√Ω d·ªØ li·ªáu thi·∫øu (Missing Data)\n",
        "print(\"üîß 5. X·ª¨ L√ù D·ªÆ LI·ªÜU THI·∫æU\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# T·∫°o d·ªØ li·ªáu c√≥ gi√° tr·ªã thi·∫øu\n",
        "print(\"üî∏ T·∫°o d·ªØ li·ªáu thi·∫øu:\")\n",
        "df_missing = df.copy()\n",
        "\n",
        "# Th√™m m·ªôt s·ªë gi√° tr·ªã NaN\n",
        "df_missing.loc[1, 'L∆∞∆°ng'] = np.nan\n",
        "df_missing.loc[3, 'Tu·ªïi'] = np.nan\n",
        "df_missing.loc[4, 'Th√†nh ph·ªë'] = np.nan\n",
        "df_missing.loc[2, 'Kinh nghi·ªám'] = np.nan\n",
        "df_missing.loc[5, 'L∆∞∆°ng'] = np.nan\n",
        "\n",
        "print(\"DataFrame v·ªõi d·ªØ li·ªáu thi·∫øu:\")\n",
        "print(df_missing)\n",
        "\n",
        "# Ki·ªÉm tra d·ªØ li·ªáu thi·∫øu\n",
        "print(\"\\nüî∏ Ki·ªÉm tra d·ªØ li·ªáu thi·∫øu:\")\n",
        "print(\"S·ªë gi√° tr·ªã thi·∫øu m·ªói c·ªôt:\")\n",
        "missing_count = df_missing.isnull().sum()\n",
        "print(missing_count)\n",
        "\n",
        "print(\"\\nPh·∫ßn trƒÉm gi√° tr·ªã thi·∫øu:\")\n",
        "missing_percent = (df_missing.isnull().sum() / len(df_missing) * 100).round(2)\n",
        "print(missing_percent)\n",
        "\n",
        "# T·ªïng h·ª£p th√¥ng tin missing data\n",
        "missing_info = pd.DataFrame({\n",
        "    'Missing_Count': missing_count,\n",
        "    'Missing_Percent': missing_percent\n",
        "})\n",
        "print(\"\\nT·ªïng h·ª£p missing data:\")\n",
        "print(missing_info[missing_info['Missing_Count'] > 0])\n",
        "\n",
        "# Ki·ªÉm tra h√†ng n√†o c√≥ d·ªØ li·ªáu thi·∫øu\n",
        "print(\"\\nH√†ng c√≥ d·ªØ li·ªáu thi·∫øu:\")\n",
        "rows_with_missing = df_missing[df_missing.isnull().any(axis=1)]\n",
        "print(rows_with_missing)"
      ],
      "metadata": {
        "id": "missing_data_detection"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X·ª≠ l√Ω d·ªØ li·ªáu thi·∫øu - c√°c ph∆∞∆°ng ph√°p kh√°c nhau\n",
        "print(\"üî∏ C√°c ph∆∞∆°ng ph√°p x·ª≠ l√Ω d·ªØ li·ªáu thi·∫øu:\")\n",
        "\n",
        "# Ph∆∞∆°ng ph√°p 1: ƒêi·ªÅn gi√° tr·ªã c·ªë ƒë·ªãnh\n",
        "print(\"\\n1. ƒêi·ªÅn gi√° tr·ªã c·ªë ƒë·ªãnh:\")\n",
        "df_filled_0 = df_missing.fillna(0)\n",
        "print(\"ƒêi·ªÅn 0 cho t·∫•t c·∫£ NaN:\")\n",
        "print(df_filled_0[['T√™n', 'Tu·ªïi', 'L∆∞∆°ng', 'Th√†nh ph·ªë', 'Kinh nghi·ªám']])\n",
        "\n",
        "# Ph∆∞∆°ng ph√°p 2: ƒêi·ªÅn gi√° tr·ªã theo c·ªôt\n",
        "print(\"\\n2. ƒêi·ªÅn gi√° tr·ªã kh√°c nhau cho t·ª´ng c·ªôt:\")\n",
        "df_filled_custom = df_missing.copy()\n",
        "df_filled_custom['Tu·ªïi'].fillna(df_filled_custom['Tu·ªïi'].mean(), inplace=True)\n",
        "df_filled_custom['L∆∞∆°ng'].fillna(df_filled_custom['L∆∞∆°ng'].median(), inplace=True)\n",
        "df_filled_custom['Kinh nghi·ªám'].fillna(df_filled_custom['Kinh nghi·ªám'].mean(), inplace=True)\n",
        "df_filled_custom['Th√†nh ph·ªë'].fillna('Unknown', inplace=True)\n",
        "\n",
        "print(\"ƒêi·ªÅn mean/median cho s·ªë, 'Unknown' cho text:\")\n",
        "print(df_filled_custom)\n",
        "\n",
        "# Ph∆∞∆°ng ph√°p 3: Forward fill v√† backward fill\n",
        "print(\"\\n3. Forward fill v√† backward fill:\")\n",
        "df_ffill = df_missing.fillna(method='ffill')  # ƒêi·ªÅn gi√° tr·ªã t·ª´ tr∆∞·ªõc\n",
        "print(\"Forward fill (ffill):\")\n",
        "print(df_ffill[['T√™n', 'Tu·ªïi', 'L∆∞∆°ng']])\n",
        "\n",
        "df_bfill = df_missing.fillna(method='bfill')  # ƒêi·ªÅn gi√° tr·ªã t·ª´ sau\n",
        "print(\"\\nBackward fill (bfill):\")\n",
        "print(df_bfill[['T√™n', 'Tu·ªïi', 'L∆∞∆°ng']])\n",
        "\n",
        "# Ph∆∞∆°ng ph√°p 4: Interpolation\n",
        "print(\"\\n4. Interpolation (cho c·ªôt s·ªë):\")\n",
        "df_interpolated = df_missing.copy()\n",
        "df_interpolated['L∆∞∆°ng'] = df_interpolated['L∆∞∆°ng'].interpolate()\n",
        "df_interpolated['Tu·ªïi'] = df_interpolated['Tu·ªïi'].interpolate()\n",
        "print(\"Interpolated values:\")\n",
        "print(df_interpolated[['T√™n', 'Tu·ªïi', 'L∆∞∆°ng']])"
      ],
      "metadata": {
        "id": "missing_data_handling"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X√≥a d·ªØ li·ªáu thi·∫øu\n",
        "print(\"\\n5. X√≥a d·ªØ li·ªáu thi·∫øu:\")\n",
        "\n",
        "# X√≥a t·∫•t c·∫£ h√†ng c√≥ NaN\n",
        "df_dropped_any = df_missing.dropna()\n",
        "print(f\"X√≥a t·∫•t c·∫£ h√†ng c√≥ NaN:\")\n",
        "print(f\"Shape tr∆∞·ªõc: {df_missing.shape}\")\n",
        "print(f\"Shape sau: {df_dropped_any.shape}\")\n",
        "print(df_dropped_any)\n",
        "\n",
        "# X√≥a h√†ng c√≥ t·∫•t c·∫£ NaN\n",
        "df_dropped_all = df_missing.dropna(how='all')\n",
        "print(f\"\\nX√≥a h√†ng c√≥ t·∫•t c·∫£ NaN:\")\n",
        "print(f\"Shape: {df_dropped_all.shape}\")\n",
        "\n",
        "# X√≥a h√†ng c√≥ NaN trong c·ªôt c·ª• th·ªÉ\n",
        "df_dropped_subset = df_missing.dropna(subset=['L∆∞∆°ng'])\n",
        "print(f\"\\nX√≥a h√†ng c√≥ NaN trong c·ªôt 'L∆∞∆°ng':\")\n",
        "print(f\"Shape: {df_dropped_subset.shape}\")\n",
        "print(df_dropped_subset[['T√™n', 'L∆∞∆°ng']])\n",
        "\n",
        "# X√≥a c·ªôt c√≥ qu√° nhi·ªÅu NaN\n",
        "threshold = len(df_missing) * 0.5  # Gi·ªØ c·ªôt c√≥ √≠t h∆°n 50% NaN\n",
        "df_dropped_cols = df_missing.dropna(thresh=threshold, axis=1)\n",
        "print(f\"\\nX√≥a c·ªôt c√≥ >50% NaN:\")\n",
        "print(f\"Columns: {df_dropped_cols.columns.tolist()}\")\n",
        "\n",
        "# Ph∆∞∆°ng ph√°p 6: Advanced filling\n",
        "print(\"\\n6. Advanced filling strategies:\")\n",
        "df_advanced = df_missing.copy()\n",
        "\n",
        "# ƒêi·ªÅn based tr√™n group\n",
        "df_advanced['L∆∞∆°ng'] = df_advanced.groupby('Th√†nh ph·ªë')['L∆∞∆°ng'].transform(\n",
        "    lambda x: x.fillna(x.mean())\n",
        ")\n",
        "\n",
        "print(\"ƒêi·ªÅn l∆∞∆°ng theo mean c·ªßa t·ª´ng th√†nh ph·ªë:\")\n",
        "print(df_advanced[['T√™n', 'Th√†nh ph·ªë', 'L∆∞∆°ng']])\n",
        "\n",
        "# So s√°nh c√°c ph∆∞∆°ng ph√°p\n",
        "print(\"\\nüìä So s√°nh c√°c ph∆∞∆°ng ph√°p:\")\n",
        "methods_comparison = pd.DataFrame({\n",
        "    'Method': ['Original', 'Fill 0', 'Fill Mean/Median', 'Drop NaN', 'Interpolate'],\n",
        "    'Shape': [df_missing.shape, df_filled_0.shape, df_filled_custom.shape,\n",
        "              df_dropped_any.shape, df_interpolated.shape],\n",
        "    'Missing_Count': [df_missing.isnull().sum().sum(), df_filled_0.isnull().sum().sum(),\n",
        "                     df_filled_custom.isnull().sum().sum(), df_dropped_any.isnull().sum().sum(),\n",
        "                     df_interpolated.isnull().sum().sum()]\n",
        "})\n",
        "print(methods_comparison)"
      ],
      "metadata": {
        "id": "missing_data_strategies"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VI. Th·ªëng k√™ v√† ph√¢n t√≠ch d·ªØ li·ªáu"
      ],
      "metadata": {
        "id": "statistics_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Th·ªëng k√™ v√† ph√¢n t√≠ch d·ªØ li·ªáu\n",
        "print(\"üìä 6. TH·ªêNG K√ä V√Ä PH√ÇN T√çCH D·ªÆ LI·ªÜU\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "# Th·ªëng k√™ c∆° b·∫£n\n",
        "print(\"üî∏ Th·ªëng k√™ c∆° b·∫£n:\")\n",
        "print(f\"L∆∞∆°ng trung b√¨nh: {df['L∆∞∆°ng'].mean():.2f}\")\n",
        "print(f\"L∆∞∆°ng trung v·ªã: {df['L∆∞∆°ng'].median():.2f}\")\n",
        "print(f\"ƒê·ªô l·ªách chu·∫©n l∆∞∆°ng: {df['L∆∞∆°ng'].std():.2f}\")\n",
        "print(f\"L∆∞∆°ng min: {df['L∆∞∆°ng'].min()}\")\n",
        "print(f\"L∆∞∆°ng max: {df['L∆∞∆°ng'].max()}\")\n",
        "print(f\"T·ªïng l∆∞∆°ng: {df['L∆∞∆°ng'].sum():,}\")\n",
        "\n",
        "print(f\"\\nTu·ªïi th·ªëng k√™:\")\n",
        "print(f\"Tu·ªïi TB: {df['Tu·ªïi'].mean():.1f}\")\n",
        "print(f\"Tu·ªïi min: {df['Tu·ªïi'].min()}\")\n",
        "print(f\"Tu·ªïi max: {df['Tu·ªïi'].max()}\")\n",
        "\n",
        "# Quartiles v√† percentiles\n",
        "print(f\"\\nüî∏ Quartiles v√† percentiles:\")\n",
        "print(f\"Q1 (25%): {df['L∆∞∆°ng'].quantile(0.25)}\")\n",
        "print(f\"Q2 (50% - Median): {df['L∆∞∆°ng'].quantile(0.5)}\")\n",
        "print(f\"Q3 (75%): {df['L∆∞∆°ng'].quantile(0.75)}\")\n",
        "print(f\"90th percentile: {df['L∆∞∆°ng'].quantile(0.9)}\")\n",
        "\n",
        "# Value counts\n",
        "print(\"\\nüî∏ ƒê·∫øm t·∫ßn su·∫•t:\")\n",
        "print(\"Ph√¢n b·ªë theo th√†nh ph·ªë:\")\n",
        "city_counts = df['Th√†nh ph·ªë'].value_counts()\n",
        "print(city_counts)\n",
        "\n",
        "print(\"\\nPh√¢n b·ªë theo ƒë·ªô tu·ªïi:\")\n",
        "age_counts = df['Tu·ªïi'].value_counts().sort_index()\n",
        "print(age_counts)\n",
        "\n",
        "print(\"\\nPh√¢n b·ªë theo kinh nghi·ªám:\")\n",
        "exp_counts = df['Kinh nghi·ªám'].value_counts().sort_index()\n",
        "print(exp_counts)\n",
        "\n",
        "# Normalize value counts (percentage)\n",
        "print(\"\\nüî∏ Ph·∫ßn trƒÉm ph√¢n b·ªë:\")\n",
        "city_percent = df['Th√†nh ph·ªë'].value_counts(normalize=True) * 100\n",
        "print(\"Ph·∫ßn trƒÉm theo th√†nh ph·ªë:\")\n",
        "print(city_percent.round(2))"
      ],
      "metadata": {
        "id": "basic_statistics"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group By operations\n",
        "print(\"üî∏ Group By operations:\")\n",
        "\n",
        "# Group by single column\n",
        "print(\"Th·ªëng k√™ theo th√†nh ph·ªë:\")\n",
        "city_stats = df.groupby('Th√†nh ph·ªë').agg({\n",
        "    'L∆∞∆°ng': ['mean', 'max', 'min', 'count'],\n",
        "    'Tu·ªïi': 'mean',\n",
        "    'Kinh nghi·ªám': ['mean', 'max']\n",
        "})\n",
        "print(city_stats)\n",
        "\n",
        "# Flatten column names\n",
        "city_stats.columns = ['_'.join(col).strip() for col in city_stats.columns]\n",
        "print(\"\\nC√πng d·ªØ li·ªáu v·ªõi column names ƒë∆°n gi·∫£n:\")\n",
        "print(city_stats)\n",
        "\n",
        "# Group by v·ªõi ƒëi·ªÅu ki·ªán\n",
        "print(\"\\nüî∏ Group by v·ªõi ƒëi·ªÅu ki·ªán:\")\n",
        "df['Age_Group'] = df['Tu·ªïi'].apply(lambda x: 'Young' if x < 30 else 'Senior')\n",
        "age_group_stats = df.groupby('Age_Group').agg({\n",
        "    'L∆∞∆°ng': ['mean', 'count'],\n",
        "    'Kinh nghi·ªám': 'mean'\n",
        "})\n",
        "print(\"Th·ªëng k√™ theo nh√≥m tu·ªïi:\")\n",
        "print(age_group_stats)\n",
        "\n",
        "# Multiple groupby\n",
        "print(\"\\nüî∏ Multiple Group By:\")\n",
        "multi_group = df.groupby(['Th√†nh ph·ªë', 'Age_Group'])['L∆∞∆°ng'].agg(['mean', 'count'])\n",
        "print(\"Th·ªëng k√™ theo th√†nh ph·ªë v√† nh√≥m tu·ªïi:\")\n",
        "print(multi_group)\n",
        "\n",
        "# Custom aggregation function\n",
        "print(\"\\nüî∏ Custom aggregation:\")\n",
        "def salary_range(series):\n",
        "    return series.max() - series.min()\n",
        "\n",
        "custom_agg = df.groupby('Th√†nh ph·ªë')['L∆∞∆°ng'].agg([\n",
        "    ('Avg_Salary', 'mean'),\n",
        "    ('Salary_Range', salary_range),\n",
        "    ('Total_Employees', 'count')\n",
        "])\n",
        "print(\"Custom aggregation:\")\n",
        "print(custom_agg)"
      ],
      "metadata": {
        "id": "groupby_operations"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation analysis\n",
        "print(\"üî∏ Correlation analysis:\")\n",
        "print(\"Ma tr·∫≠n t∆∞∆°ng quan gi·ªØa c√°c bi·∫øn s·ªë:\")\n",
        "correlation_matrix = df[['Tu·ªïi', 'L∆∞∆°ng', 'Kinh nghi·ªám']].corr()\n",
        "print(correlation_matrix)\n",
        "\n",
        "print(\"\\nT∆∞∆°ng quan m·∫°nh nh·∫•t:\")\n",
        "# T√¨m correlation cao nh·∫•t (kh√¥ng t√≠nh diagonal)\n",
        "corr_values = correlation_matrix.values\n",
        "np.fill_diagonal(corr_values, 0)  # Set diagonal to 0\n",
        "max_corr_idx = np.unravel_index(np.argmax(np.abs(corr_values)), corr_values.shape)\n",
        "cols = correlation_matrix.columns\n",
        "print(f\"T∆∞∆°ng quan cao nh·∫•t: {cols[max_corr_idx[0]]} vs {cols[max_corr_idx[1]]} = {corr_values[max_corr_idx]:.3f}\")\n",
        "\n",
        "# Pivot table\n",
        "print(\"\\nüî∏ Pivot Table:\")\n",
        "pivot = df.pivot_table(\n",
        "    values='L∆∞∆°ng',\n",
        "    index='Th√†nh ph·ªë',\n",
        "    columns='Age_Group',\n",
        "    aggfunc=['mean', 'count'],\n",
        "    fill_value=0\n",
        ")\n",
        "print(\"Pivot table - L∆∞∆°ng theo th√†nh ph·ªë v√† nh√≥m tu·ªïi:\")\n",
        "print(pivot)\n",
        "\n",
        "# Cross tabulation\n",
        "print(\"\\nüî∏ Cross Tabulation:\")\n",
        "crosstab = pd.crosstab(df['Th√†nh ph·ªë'], df['Age_Group'], margins=True)\n",
        "print(\"Cross tabulation - S·ªë l∆∞·ª£ng nh√¢n vi√™n:\")\n",
        "print(crosstab)\n",
        "\n",
        "# Percentage cross tabulation\n",
        "crosstab_pct = pd.crosstab(df['Th√†nh ph·ªë'], df['Age_Group'], normalize='index') * 100\n",
        "print(\"\\nCross tabulation (percentage by city):\")\n",
        "print(crosstab_pct.round(2))"
      ],
      "metadata": {
        "id": "advanced_analysis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# üéØ **PH·∫¶N 3: B√ÄI T·∫¨P TH·ª∞C H√ÄNH**\n",
        "\n",
        "## B√†i t·∫≠p t·ªïng h·ª£p ki·∫øn th·ª©c NumPy v√† Pandas"
      ],
      "metadata": {
        "id": "exercises_header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üî¢ **B√ÄI T·∫¨P NUMPY**"
      ],
      "metadata": {
        "id": "numpy_exercises_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# B√†i t·∫≠p NumPy\n",
        "print(\"üî¢ B√ÄI T·∫¨P NUMPY\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "print(\"\\nüìù B√†i t·∫≠p 1: T·∫°o v√† thao t√°c m·∫£ng c∆° b·∫£n\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# T·∫°o m·∫£ng 2D t·ª´ 1 ƒë·∫øn 20, reshape th√†nh 4x5\n",
        "matrix = np.arange(1, 21).reshape(4, 5)\n",
        "print(f\"Ma tr·∫≠n 4x5:\")\n",
        "print(matrix)\n",
        "\n",
        "# T√≠nh t·ªïng t·ª´ng h√†ng v√† t·ª´ng c·ªôt\n",
        "row_sums = np.sum(matrix, axis=1)\n",
        "col_sums = np.sum(matrix, axis=0)\n",
        "print(f\"\\nT·ªïng t·ª´ng h√†ng: {row_sums}\")\n",
        "print(f\"T·ªïng t·ª´ng c·ªôt: {col_sums}\")\n",
        "\n",
        "# T√¨m gi√° tr·ªã l·ªõn nh·∫•t v√† nh·ªè nh·∫•t\n",
        "print(f\"\\nGi√° tr·ªã l·ªõn nh·∫•t: {np.max(matrix)}\")\n",
        "print(f\"Gi√° tr·ªã nh·ªè nh·∫•t: {np.min(matrix)}\")\n",
        "print(f\"V·ªã tr√≠ max: {np.unravel_index(np.argmax(matrix), matrix.shape)}\")\n",
        "print(f\"V·ªã tr√≠ min: {np.unravel_index(np.argmin(matrix), matrix.shape)}\")\n",
        "\n",
        "# T√≠nh trung b√¨nh\n",
        "print(f\"\\nTrung b√¨nh to√†n b·ªô: {np.mean(matrix):.2f}\")\n",
        "print(f\"Trung b√¨nh t·ª´ng h√†ng: {np.mean(matrix, axis=1)}\")\n",
        "print(f\"Trung b√¨nh t·ª´ng c·ªôt: {np.mean(matrix, axis=0)}\")\n",
        "\n",
        "print(\"\\nüìù B√†i t·∫≠p 2: Broadcasting v√† ph√©p to√°n\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# T·∫°o m·∫£ng v√† vector\n",
        "A = np.random.randint(1, 10, (3, 4))\n",
        "v = np.array([1, 2, 3, 4])\n",
        "\n",
        "print(f\"Ma tr·∫≠n A (3x4):\")\n",
        "print(A)\n",
        "print(f\"\\nVector v: {v}\")\n",
        "\n",
        "# Broadcasting operations\n",
        "print(f\"\\nA + v (broadcasting):\")\n",
        "print(A + v)\n",
        "\n",
        "print(f\"\\nA * v (broadcasting):\")\n",
        "print(A * v)\n",
        "\n",
        "# Normalize rows (chia m·ªói h√†ng cho t·ªïng c·ªßa n√≥)\n",
        "row_sums = np.sum(A, axis=1, keepdims=True)\n",
        "normalized = A / row_sums\n",
        "print(f\"\\nNormalized rows (sum=1):\")\n",
        "print(normalized)\n",
        "print(f\"\\nKi·ªÉm tra t·ªïng t·ª´ng h√†ng: {np.sum(normalized, axis=1)}\")"
      ],
      "metadata": {
        "id": "numpy_exercises"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüìù B√†i t·∫≠p 3: Dot product th·ª±c t·∫ø\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Scenario: Portfolio investment\n",
        "print(\"üè¶ Scenario: T√≠nh to√°n portfolio ƒë·∫ßu t∆∞\")\n",
        "\n",
        "# Stock prices v√† quantities\n",
        "stocks = ['AAPL', 'GOOGL', 'MSFT', 'TSLA', 'AMZN']\n",
        "prices = np.array([150, 2500, 300, 800, 3200])  # Gi√° c·ªï phi·∫øu\n",
        "quantities = np.array([10, 2, 5, 3, 1])         # S·ªë l∆∞·ª£ng s·ªü h·ªØu\n",
        "\n",
        "print(f\"Stocks: {stocks}\")\n",
        "print(f\"Prices: {prices}\")\n",
        "print(f\"Quantities: {quantities}\")\n",
        "\n",
        "# T·ªïng gi√° tr·ªã portfolio\n",
        "total_value = np.dot(prices, quantities)\n",
        "print(f\"\\nüí∞ T·ªïng gi√° tr·ªã portfolio: ${total_value:,}\")\n",
        "\n",
        "# Weight c·ªßa m·ªói stock\n",
        "weights = (prices * quantities) / total_value\n",
        "print(f\"\\nüìä T·ª∑ tr·ªçng t·ª´ng c·ªï phi·∫øu:\")\n",
        "for stock, weight in zip(stocks, weights):\n",
        "    print(f\"  {stock}: {weight:.2%}\")\n",
        "\n",
        "# Gi·∫£ s·ª≠ gi√° thay ƒë·ªïi +5%, -3%, +2%, +10%, -1%\n",
        "price_changes = np.array([0.05, -0.03, 0.02, 0.10, -0.01])\n",
        "new_prices = prices * (1 + price_changes)\n",
        "new_value = np.dot(new_prices, quantities)\n",
        "\n",
        "print(f\"\\nüìà Sau khi gi√° thay ƒë·ªïi:\")\n",
        "print(f\"New prices: {new_prices}\")\n",
        "print(f\"New portfolio value: ${new_value:,}\")\n",
        "print(f\"Change: ${new_value - total_value:,.2f} ({((new_value - total_value)/total_value):.2%})\")\n",
        "\n",
        "print(\"\\nüìù B√†i t·∫≠p 4: Matrix operations\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Transformation matrix\n",
        "print(\"üîÑ Linear transformation\")\n",
        "\n",
        "# Points to transform\n",
        "points = np.array([[1, 2], [3, 4], [5, 6]])  # 3 points in 2D\n",
        "print(f\"Original points:\")\n",
        "print(points)\n",
        "\n",
        "# Rotation matrix (45 degrees)\n",
        "angle = np.pi / 4  # 45 degrees in radians\n",
        "rotation_matrix = np.array([\n",
        "    [np.cos(angle), -np.sin(angle)],\n",
        "    [np.sin(angle), np.cos(angle)]\n",
        "])\n",
        "\n",
        "print(f\"\\nRotation matrix (45¬∞):\")\n",
        "print(rotation_matrix)\n",
        "\n",
        "# Apply transformation\n",
        "transformed_points = points @ rotation_matrix.T\n",
        "print(f\"\\nTransformed points:\")\n",
        "print(transformed_points)\n",
        "\n",
        "# Scaling matrix\n",
        "scale_matrix = np.array([[2, 0], [0, 3]])  # Scale x by 2, y by 3\n",
        "scaled_points = points @ scale_matrix.T\n",
        "print(f\"\\nScaled points (2x, 3y):\")\n",
        "print(scaled_points)"
      ],
      "metadata": {
        "id": "numpy_advanced_exercises"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üêº **B√ÄI T·∫¨P PANDAS**"
      ],
      "metadata": {
        "id": "pandas_exercises_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# B√†i t·∫≠p Pandas\n",
        "print(\"üêº B√ÄI T·∫¨P PANDAS\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "print(\"\\nüìù B√†i t·∫≠p 1: Ph√¢n t√≠ch d·ªØ li·ªáu sinh vi√™n\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# T·∫°o dataset sinh vi√™n\n",
        "np.random.seed(42)\n",
        "n_students = 100\n",
        "\n",
        "students_data = {\n",
        "    'StudentID': [f'ST{i+1:03d}' for i in range(n_students)],\n",
        "    'Name': [f'Student_{i+1}' for i in range(n_students)],\n",
        "    'Math': np.random.normal(75, 15, n_students).clip(0, 100),\n",
        "    'Physics': np.random.normal(70, 12, n_students).clip(0, 100),\n",
        "    'Chemistry': np.random.normal(72, 14, n_students).clip(0, 100),\n",
        "    'English': np.random.normal(78, 10, n_students).clip(0, 100),\n",
        "    'Class': np.random.choice(['A', 'B', 'C', 'D'], n_students),\n",
        "    'Gender': np.random.choice(['Male', 'Female'], n_students),\n",
        "    'Age': np.random.randint(18, 23, n_students)\n",
        "}\n",
        "\n",
        "df_students = pd.DataFrame(students_data)\n",
        "\n",
        "# L√†m tr√≤n ƒëi·ªÉm s·ªë\n",
        "df_students[['Math', 'Physics', 'Chemistry', 'English']] = df_students[['Math', 'Physics', 'Chemistry', 'English']].round(1)\n",
        "\n",
        "print(\"Dataset sinh vi√™n (10 d√≤ng ƒë·∫ßu):\")\n",
        "print(df_students.head(10))\n",
        "\n",
        "print(f\"\\nüìä Th√¥ng tin c∆° b·∫£n:\")\n",
        "print(f\"T·ªïng s·ªë sinh vi√™n: {len(df_students)}\")\n",
        "print(f\"S·ªë l·ªõp: {df_students['Class'].nunique()}\")\n",
        "print(f\"Ph√¢n b·ªë gi·ªõi t√≠nh:\\n{df_students['Gender'].value_counts()}\")\n",
        "print(f\"ƒê·ªô tu·ªïi: {df_students['Age'].min()}-{df_students['Age'].max()}\")"
      ],
      "metadata": {
        "id": "pandas_student_dataset"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ph√¢n t√≠ch d·ªØ li·ªáu sinh vi√™n\n",
        "print(\"\\nüî∏ T√≠nh ƒëi·ªÉm trung b√¨nh v√† x·∫øp lo·∫°i:\")\n",
        "\n",
        "# T√≠nh ƒëi·ªÉm trung b√¨nh\n",
        "subject_columns = ['Math', 'Physics', 'Chemistry', 'English']\n",
        "df_students['Average'] = df_students[subject_columns].mean(axis=1)\n",
        "\n",
        "# T·∫°o c·ªôt x·∫øp lo·∫°i\n",
        "def classify_grade(avg):\n",
        "    if avg >= 85:\n",
        "        return 'Excellent'\n",
        "    elif avg >= 75:\n",
        "        return 'Good'\n",
        "    elif avg >= 65:\n",
        "        return 'Average'\n",
        "    elif avg >= 50:\n",
        "        return 'Below Average'\n",
        "    else:\n",
        "        return 'Poor'\n",
        "\n",
        "df_students['Grade'] = df_students['Average'].apply(classify_grade)\n",
        "\n",
        "print(\"Top 10 sinh vi√™n c√≥ ƒëi·ªÉm TB cao nh·∫•t:\")\n",
        "top_students = df_students.nlargest(10, 'Average')[['Name', 'Class', 'Average', 'Grade']]\n",
        "print(top_students)\n",
        "\n",
        "print(\"\\nüî∏ Ph√¢n b·ªë x·∫øp lo·∫°i:\")\n",
        "grade_distribution = df_students['Grade'].value_counts()\n",
        "print(grade_distribution)\n",
        "print(\"\\nPh·∫ßn trƒÉm:\")\n",
        "print((grade_distribution / len(df_students) * 100).round(2))\n",
        "\n",
        "print(\"\\nüî∏ Th·ªëng k√™ theo l·ªõp:\")\n",
        "class_stats = df_students.groupby('Class').agg({\n",
        "    'Average': ['mean', 'max', 'min', 'std'],\n",
        "    'Name': 'count'\n",
        "}).round(2)\n",
        "class_stats.columns = ['Avg_Score', 'Max_Score', 'Min_Score', 'Std_Score', 'Student_Count']\n",
        "print(class_stats)\n",
        "\n",
        "print(\"\\nüî∏ Th·ªëng k√™ theo gi·ªõi t√≠nh:\")\n",
        "gender_stats = df_students.groupby('Gender')[subject_columns + ['Average']].mean().round(2)\n",
        "print(gender_stats)\n",
        "\n",
        "print(\"\\nüî∏ T∆∞∆°ng quan gi·ªØa c√°c m√¥n h·ªçc:\")\n",
        "subject_correlation = df_students[subject_columns].corr().round(3)\n",
        "print(subject_correlation)"
      ],
      "metadata": {
        "id": "student_analysis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüìù B√†i t·∫≠p 2: Ph√¢n t√≠ch d·ªØ li·ªáu b√°n h√†ng\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# T·∫°o dataset b√°n h√†ng\n",
        "np.random.seed(123)\n",
        "n_transactions = 1000\n",
        "\n",
        "# T·∫°o date range\n",
        "date_range = pd.date_range('2024-01-01', '2024-12-31', freq='D')\n",
        "products = ['Laptop', 'Phone', 'Tablet', 'Watch', 'Headphones', 'Speaker', 'Camera']\n",
        "regions = ['North', 'South', 'East', 'West', 'Central']\n",
        "salespersons = [f'Sales_{i+1}' for i in range(20)]\n",
        "\n",
        "sales_data = {\n",
        "    'TransactionID': [f'T{i+1:04d}' for i in range(n_transactions)],\n",
        "    'Date': np.random.choice(date_range, n_transactions),\n",
        "    'Product': np.random.choice(products, n_transactions),\n",
        "    'Quantity': np.random.randint(1, 5, n_transactions),\n",
        "    'Unit_Price': np.random.uniform(100, 1500, n_transactions).round(2),\n",
        "    'Region': np.random.choice(regions, n_transactions),\n",
        "    'Salesperson': np.random.choice(salespersons, n_transactions),\n",
        "    'Customer_Type': np.random.choice(['New', 'Returning'], n_transactions, p=[0.3, 0.7])\n",
        "}\n",
        "\n",
        "df_sales = pd.DataFrame(sales_data)\n",
        "\n",
        "# T√≠nh revenue\n",
        "df_sales['Revenue'] = df_sales['Quantity'] * df_sales['Unit_Price']\n",
        "\n",
        "# Extract time features\n",
        "df_sales['Year'] = df_sales['Date'].dt.year\n",
        "df_sales['Month'] = df_sales['Date'].dt.month\n",
        "df_sales['Quarter'] = df_sales['Date'].dt.quarter\n",
        "df_sales['Day_of_Week'] = df_sales['Date'].dt.day_name()\n",
        "\n",
        "print(\"Dataset b√°n h√†ng (10 d√≤ng ƒë·∫ßu):\")\n",
        "print(df_sales.head(10))\n",
        "\n",
        "print(f\"\\nüìä T·ªïng quan:\")\n",
        "print(f\"T·ªïng s·ªë giao d·ªãch: {len(df_sales):,}\")\n",
        "print(f\"T·ªïng doanh thu: ${df_sales['Revenue'].sum():,.2f}\")\n",
        "print(f\"Doanh thu trung b√¨nh/giao d·ªãch: ${df_sales['Revenue'].mean():.2f}\")\n",
        "print(f\"Giao d·ªãch l·ªõn nh·∫•t: ${df_sales['Revenue'].max():,.2f}\")\n",
        "print(f\"S·ªë s·∫£n ph·∫©m: {df_sales['Product'].nunique()}\")\n",
        "print(f\"S·ªë v√πng: {df_sales['Region'].nunique()}\")\n",
        "print(f\"S·ªë nh√¢n vi√™n b√°n h√†ng: {df_sales['Salesperson'].nunique()}\")"
      ],
      "metadata": {
        "id": "sales_dataset"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ph√¢n t√≠ch b√°n h√†ng chi ti·∫øt\n",
        "print(\"\\nüî∏ Ph√¢n t√≠ch theo s·∫£n ph·∫©m:\")\n",
        "product_analysis = df_sales.groupby('Product').agg({\n",
        "    'Revenue': ['sum', 'mean', 'count'],\n",
        "    'Quantity': 'sum',\n",
        "    'Unit_Price': 'mean'\n",
        "}).round(2)\n",
        "\n",
        "product_analysis.columns = ['Total_Revenue', 'Avg_Revenue', 'Transaction_Count', 'Total_Quantity', 'Avg_Price']\n",
        "product_analysis = product_analysis.sort_values('Total_Revenue', ascending=False)\n",
        "print(product_analysis)\n",
        "\n",
        "print(\"\\nüî∏ Ph√¢n t√≠ch theo v√πng:\")\n",
        "region_analysis = df_sales.groupby('Region').agg({\n",
        "    'Revenue': ['sum', 'mean'],\n",
        "    'TransactionID': 'count'\n",
        "}).round(2)\n",
        "region_analysis.columns = ['Total_Revenue', 'Avg_Revenue', 'Transaction_Count']\n",
        "region_analysis['Revenue_Share'] = (region_analysis['Total_Revenue'] / region_analysis['Total_Revenue'].sum() * 100).round(2)\n",
        "print(region_analysis.sort_values('Total_Revenue', ascending=False))\n",
        "\n",
        "print(\"\\nüî∏ Ph√¢n t√≠ch theo th√°ng:\")\n",
        "monthly_analysis = df_sales.groupby('Month').agg({\n",
        "    'Revenue': 'sum',\n",
        "    'TransactionID': 'count'\n",
        "}).round(2)\n",
        "monthly_analysis.columns = ['Total_Revenue', 'Transaction_Count']\n",
        "monthly_analysis['Avg_Revenue_per_Transaction'] = (monthly_analysis['Total_Revenue'] / monthly_analysis['Transaction_Count']).round(2)\n",
        "print(monthly_analysis)\n",
        "\n",
        "print(\"\\nüî∏ Top 10 nh√¢n vi√™n b√°n h√†ng:\")\n",
        "top_salespeople = df_sales.groupby('Salesperson').agg({\n",
        "    'Revenue': 'sum',\n",
        "    'TransactionID': 'count'\n",
        "}).round(2)\n",
        "top_salespeople.columns = ['Total_Revenue', 'Transaction_Count']\n",
        "top_salespeople['Avg_Revenue_per_Transaction'] = (top_salespeople['Total_Revenue'] / top_salespeople['Transaction_Count']).round(2)\n",
        "top_salespeople = top_salespeople.sort_values('Total_Revenue', ascending=False).head(10)\n",
        "print(top_salespeople)\n",
        "\n",
        "print(\"\\nüî∏ Ph√¢n t√≠ch theo lo·∫°i kh√°ch h√†ng:\")\n",
        "customer_analysis = df_sales.groupby('Customer_Type').agg({\n",
        "    'Revenue': ['sum', 'mean', 'count']\n",
        "}).round(2)\n",
        "customer_analysis.columns = ['Total_Revenue', 'Avg_Revenue', 'Transaction_Count']\n",
        "print(customer_analysis)\n",
        "\n",
        "print(\"\\nüî∏ Ph√¢n t√≠ch theo ng√†y trong tu·∫ßn:\")\n",
        "day_analysis = df_sales.groupby('Day_of_Week').agg({\n",
        "    'Revenue': ['sum', 'mean'],\n",
        "    'TransactionID': 'count'\n",
        "}).round(2)\n",
        "day_analysis.columns = ['Total_Revenue', 'Avg_Revenue', 'Transaction_Count']\n",
        "# Reorder by day of week\n",
        "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "day_analysis = day_analysis.reindex(day_order)\n",
        "print(day_analysis)"
      ],
      "metadata": {
        "id": "sales_analysis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# üéâ **K·∫æT LU·∫¨N V√Ä B∆Ø·ªöC TI·∫æP THEO**\n",
        "\n",
        "## üìö **T√≥m t·∫Øt ki·∫øn th·ª©c ƒë√£ h·ªçc:**\n",
        "\n",
        "### **NumPy:**\n",
        "- ‚úÖ T·∫°o v√† thao t√°c m·∫£ng ƒëa chi·ªÅu\n",
        "- ‚úÖ Indexing, slicing, broadcasting\n",
        "- ‚úÖ C√°c ph√©p to√°n to√°n h·ªçc v√† th·ªëng k√™\n",
        "- ‚úÖ Dot product v√† linear algebra\n",
        "- ‚úÖ Random number generation\n",
        "\n",
        "### **Pandas:**\n",
        "- ‚úÖ Series v√† DataFrame\n",
        "- ‚úÖ ƒê·ªçc, ghi, v√† thao t√°c d·ªØ li·ªáu\n",
        "- ‚úÖ L·ªçc v√† t√¨m ki·∫øm d·ªØ li·ªáu\n",
        "- ‚úÖ X·ª≠ l√Ω d·ªØ li·ªáu thi·∫øu\n",
        "- ‚úÖ Group by v√† aggregation\n",
        "- ‚úÖ Th·ªëng k√™ v√† ph√¢n t√≠ch d·ªØ li·ªáu\n",
        "\n",
        "## üöÄ **B∆∞·ªõc ti·∫øp theo:**\n",
        "1. **Matplotlib/Seaborn** - Visualization\n",
        "2. **Scikit-learn** - Machine Learning\n",
        "3. **Jupyter Notebook** - Interactive analysis\n",
        "4. **Real projects** - √Åp d·ª•ng v√†o d·ª± √°n th·ª±c t·∫ø\n",
        "\n",
        "## üí° **Tips ƒë·ªÉ th√†nh th·∫°o:**\n",
        "- Th·ª±c h√†nh h√†ng ng√†y v·ªõi dataset th·∫≠t\n",
        "- Tham gia c√°c competition tr√™n Kaggle\n",
        "- ƒê·ªçc documentation v√† examples\n",
        "- Build portfolio projects\n",
        "\n",
        "---\n",
        "**üéì Ch√∫c b·∫°n h·ªçc t·∫≠p hi·ªáu qu·∫£ v√† th√†nh c√¥ng v·ªõi Data Science!**"
      ],
      "metadata": {
        "id": "conclusion"
      }
    }
  ]
}