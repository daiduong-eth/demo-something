{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "BU·ªîI 5: NUMPY V√Ä PANDAS\n"
      ],
      "metadata": {
        "id": "title_header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I. Gi·ªõi thi·ªáu NumPy\n",
        "\n",
        "NumPy l√† th∆∞ vi·ªán c∆° b·∫£n cho t√≠nh to√°n khoa h·ªçc trong Python:\n",
        "- **M·∫£ng ƒëa chi·ªÅu** hi·ªáu su·∫•t cao (ndarray)\n",
        "- **C√°c h√†m to√°n h·ªçc** ƒë·ªÉ thao t√°c v·ªõi m·∫£ng  \n",
        "- **C√¥ng c·ª•** cho ƒë·∫°i s·ªë tuy·∫øn t√≠nh, bi·∫øn ƒë·ªïi Fourier\n",
        "- **Broadcasting** v√† vectorization"
      ],
      "metadata": {
        "id": "numpy_intro_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0. T·∫°i sao n√™n d√πng c√°c th∆∞ vi·ªán nh∆∞ Numpy\n",
        "import numpy as np\n",
        "import time\n",
        "import sys\n",
        "\n",
        "size = 1000000\n",
        "python_list = list(range(size))\n",
        "numpy_array = np.arange(size)\n",
        "start_time = time.time()\n",
        "sum_list = sum(python_list)\n",
        "list_time = time.time() - start_time\n",
        "\n",
        "start_time = time.time()\n",
        "sum_numpy = np.sum(numpy_array)\n",
        "numpy_time = time.time() - start_time\n",
        "\n",
        "print(f\"Python List: {list_time:.6f}s\")\n",
        "print(f\"NumPy Array: {numpy_time:.6f}s\")\n",
        "print(f\"NumPy nhanh h∆°n: {list_time/numpy_time:.1f} l·∫ßn\")\n",
        "\n"
      ],
      "metadata": {
        "id": "numpy_performance_test",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c026c9a8-1a10-4013-a56e-65cc88465bc3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python List: 0.022285s\n",
            "NumPy Array: 0.001230s\n",
            "NumPy nhanh h∆°n: 18.1 l·∫ßn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. C√†i ƒë·∫∑t v√† import\n",
        "import numpy as np\n",
        "print(np.__version__)"
      ],
      "metadata": {
        "id": "numpy_install",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b7353a7-cbc3-45f0-9e64-5bb85368f2c0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## II. T·∫°o m·∫£ng NumPy"
      ],
      "metadata": {
        "id": "array_creation_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. T·∫°o m·∫£ng c∆° b·∫£n\n",
        "print(\"üî∏ 2.1 T·∫°o m·∫£ng t·ª´ lists/tuples:\")\n",
        "arr = np.array([1, 2, 3, 4, 5])\n",
        "print(f\"1D array: {arr}\")\n",
        "print(f\"Type: {type(arr)}\")\n",
        "\n",
        "# M·∫£ng 2D\n",
        "arr2d = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "print(f\"\\n2D array:\\n{arr2d}\")\n",
        "\n",
        "# T·ª´ tuple\n",
        "arr_tuple = np.array((7, 8, 9))\n",
        "print(f\"\\nFrom tuple: {arr_tuple}\")\n",
        "\n",
        "# Ki·ªÉu c·ªßa m·∫£ng - auto detection\n",
        "arr_mixed = np.array([1.1, 2, 3, 4, 5])  # s·∫Ω th√†nh float\n",
        "print(f\"\\nMixed types: {arr_mixed}\")\n",
        "print(f\"Auto dtype: {arr_mixed.dtype}\")"
      ],
      "metadata": {
        "id": "basic_array_creation"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Thu·ªôc t√≠nh c∆° b·∫£n c·ªßa m·∫£ng\n",
        "print(\"üìä Thu·ªôc t√≠nh c∆° b·∫£n:\")\n",
        "sample_arr = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "\n",
        "print(f\"Array:\\n{sample_arr}\")\n",
        "print(f\"üìê Shape: {sample_arr.shape}\")      # K√≠ch th∆∞·ªõc\n",
        "print(f\"üî¢ Dimensions (ndim): {sample_arr.ndim}\")  # S·ªë chi·ªÅu\n",
        "print(f\"üì¶ Size: {sample_arr.size}\")        # T·ªïng s·ªë ph·∫ßn t·ª≠\n",
        "print(f\"üè∑Ô∏è  Data type: {sample_arr.dtype}\")  # Ki·ªÉu d·ªØ li·ªáu\n",
        "print(f\"üíæ Item size: {sample_arr.itemsize} bytes\")  # K√≠ch th∆∞·ªõc m·ªói ph·∫ßn t·ª≠\n",
        "print(f\"üìä Total bytes: {sample_arr.nbytes} bytes\")  # T·ªïng b·ªô nh·ªõ"
      ],
      "metadata": {
        "id": "array_attributes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# C√°c h√†m t·∫°o m·∫£ng ƒë·∫∑c bi·ªát\n",
        "print(\"üî∏ 2.2 C√°c h√†m t·∫°o m·∫£ng ƒë·∫∑c bi·ªát:\")\n",
        "\n",
        "# Empty array - kh√¥ng kh·ªüi t·∫°o gi√° tr·ªã (nhanh nh·∫•t)\n",
        "empty_arr = np.empty((3, 3))\n",
        "print(f\"Empty array (3x3):\\n{empty_arr}\")\n",
        "\n",
        "# Ma tr·∫≠n ƒë∆°n v·ªã\n",
        "print(f\"\\nüî∏ Ma tr·∫≠n ƒë∆°n v·ªã:\")\n",
        "eye_arr = np.eye(4, 6)  # 4 h√†ng, 6 c·ªôt\n",
        "print(f\"Eye (4x6):\\n{eye_arr}\")\n",
        "\n",
        "identity_arr = np.identity(4)  # Lu√¥n vu√¥ng\n",
        "print(f\"\\nIdentity (4x4):\\n{identity_arr}\")\n",
        "\n",
        "# Ma tr·∫≠n 0 v√† 1\n",
        "print(f\"\\nüî∏ Ma tr·∫≠n zeros v√† ones:\")\n",
        "zeros_arr = np.zeros((3, 3))\n",
        "print(f\"Zeros (3x3):\\n{zeros_arr}\")\n",
        "\n",
        "# V·ªõi dtype kh√°c\n",
        "zeros_int = np.zeros((3, 3), dtype=int)\n",
        "print(f\"\\nZeros int:\\n{zeros_int}\")\n",
        "\n",
        "ones_arr = np.ones((5, 7))\n",
        "print(f\"\\nOnes (5x7):\\n{ones_arr}\")\n",
        "\n",
        "# Th·ª≠ dtype string\n",
        "ones_str = np.ones((2, 3), dtype=str)\n",
        "print(f\"\\nOnes string:\\n{ones_str}\")"
      ],
      "metadata": {
        "id": "special_array_functions"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T·∫°o d√£y s·ªë v·ªõi arange\n",
        "print(\"üî∏ 2.3 T·∫°o d√£y s·ªë v·ªõi arange:\")\n",
        "print(\"C√∫ ph√°p: np.arange(start, stop, step, dtype)\")\n",
        "\n",
        "arr1 = np.arange(5)  # 0 ƒë·∫øn 4\n",
        "print(f\"arange(5): {arr1}\")\n",
        "\n",
        "arr2 = np.arange(2, 8)  # 2 ƒë·∫øn 7\n",
        "print(f\"arange(2, 8): {arr2}\")\n",
        "\n",
        "arr3 = np.arange(0, 10, 2)  # 0 ƒë·∫øn 8, b∆∞·ªõc 2\n",
        "print(f\"arange(0, 10, 2): {arr3}\")\n",
        "\n",
        "arr4 = np.arange(10, 0, -1)  # 10 ƒë·∫øn 1, ƒë·∫øm ng∆∞·ª£c\n",
        "print(f\"arange(10, 0, -1): {arr4}\")\n",
        "\n",
        "# V·ªõi float\n",
        "arr_float = np.arange(0, 1, 0.1)\n",
        "print(f\"\\narange float (0, 1, 0.1): {arr_float}\")\n",
        "\n",
        "# Full array\n",
        "print(f\"\\nüî∏ Full array:\")\n",
        "full_arr = np.full((4, 6), 5)\n",
        "print(f\"Full with 5 (4x6):\\n{full_arr}\")\n",
        "\n",
        "# Linspace - s·ªë l∆∞·ª£ng ph·∫ßn t·ª≠ x√°c ƒë·ªãnh\n",
        "print(f\"\\nüî∏ Linspace:\")\n",
        "linspace_arr = np.linspace(0, 10, 5)  # 5 s·ªë t·ª´ 0 ƒë·∫øn 10\n",
        "print(f\"linspace(0, 10, 5): {linspace_arr}\")\n",
        "\n",
        "# So s√°nh arange vs linspace\n",
        "print(f\"\\nüí° So s√°nh:\")\n",
        "print(f\"arange: Bi·∫øt b∆∞·ªõc nh·∫£y\")\n",
        "print(f\"linspace: Bi·∫øt s·ªë ph·∫ßn t·ª≠\")"
      ],
      "metadata": {
        "id": "arange_linspace"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T·∫°o m·∫£ng ng·∫´u nhi√™n\n",
        "print(\"üî∏ 2.4 M·∫£ng ng·∫´u nhi√™n:\")\n",
        "\n",
        "# Set seed cho reproducibility\n",
        "np.random.seed(2210)\n",
        "print(\"üå± Seed = 2210 (c√≥ th·ªÉ t√°i t·∫°o k·∫øt qu·∫£)\")\n",
        "\n",
        "# Random [0, 1)\n",
        "random_arr = np.random.random((3, 3))\n",
        "print(f\"\\nRandom [0,1):\\n{random_arr}\")\n",
        "\n",
        "# Random integers\n",
        "random_int = np.random.randint(1, 10, (3, 3))\n",
        "print(f\"\\nRandom integers [1,10):\\n{random_int}\")\n",
        "\n",
        "# Normal distribution\n",
        "normal_arr = np.random.randn(2, 3)  # mean=0, std=1\n",
        "print(f\"\\nNormal distribution:\\n{normal_arr}\")\n",
        "\n",
        "# Custom normal\n",
        "custom_normal = np.random.normal(100, 15, (2, 3))  # mean=100, std=15\n",
        "print(f\"\\nCustom normal (mean=100, std=15):\\n{custom_normal}\")\n",
        "\n",
        "# Random choice\n",
        "choices = np.random.choice(['A', 'B', 'C'], size=10)\n",
        "print(f\"\\nRandom choice: {choices}\")\n",
        "\n",
        "# Weighted choice\n",
        "weighted = np.random.choice(['Win', 'Lose'], size=10, p=[0.7, 0.3])\n",
        "print(f\"Weighted choice (70% Win): {weighted}\")"
      ],
      "metadata": {
        "id": "random_arrays"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## III. Indexing v√† Slicing"
      ],
      "metadata": {
        "id": "indexing_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Indexing v√† Slicing\n",
        "print(\"üéØ 3. INDEXING V√Ä SLICING\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# T·∫°o m·∫£ng m·∫´u\n",
        "arr = np.random.randint(0, 10, (5))\n",
        "arr2 = np.random.randint(0, 10, (3, 5))\n",
        "arr3 = np.random.randint(0, 10, (3, 3, 3))\n",
        "\n",
        "print(f\"1D array: {arr}\")\n",
        "print(f\"2D array:\\n{arr2}\")\n",
        "print(f\"3D array shape: {arr3.shape}\")\n",
        "\n",
        "# 1D Indexing\n",
        "print(f\"\\nüî∏ 1D Indexing:\")\n",
        "print(f\"arr[0] = {arr[0]}\")\n",
        "print(f\"arr[3] = {arr[3]}\")\n",
        "print(f\"arr[-1] = {arr[-1]}\")\n",
        "print(f\"arr[-4] = {arr[-4]}\")\n",
        "\n",
        "# 1D Slicing\n",
        "print(f\"\\nüî∏ 1D Slicing:\")\n",
        "print(f\"arr[1:4] = {arr[1:4]}\")\n",
        "print(f\"arr[:3] = {arr[:3]}\")\n",
        "print(f\"arr[2:] = {arr[2:]}\")\n",
        "print(f\"arr[::2] = {arr[::2]}\")\n",
        "print(f\"arr[::-1] = {arr[::-1]}\")"
      ],
      "metadata": {
        "id": "indexing_1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2D Indexing v√† Slicing\n",
        "print(f\"üî∏ 2D Indexing:\")\n",
        "print(f\"2D array:\\n{arr2}\")\n",
        "\n",
        "print(f\"\\nBasic 2D indexing:\")\n",
        "print(f\"arr2[0, 0] = {arr2[0, 0]}\")\n",
        "print(f\"arr2[1, 2] = {arr2[1, 2]}\")\n",
        "print(f\"arr2[-1, -1] = {arr2[-1, -1]}\")\n",
        "print(f\"arr2[2, 1] = {arr2[2, 1]}\")\n",
        "\n",
        "print(f\"\\nüî∏ 2D Slicing:\")\n",
        "print(f\"H√†ng ƒë·∫ßu arr2[0, :] = {arr2[0, :]}\")\n",
        "print(f\"C·ªôt ƒë·∫ßu arr2[:, 0] = {arr2[:, 0]}\")\n",
        "print(f\"H√†ng cu·ªëi arr2[-1, :] = {arr2[-1, :]}\")\n",
        "print(f\"C·ªôt cu·ªëi arr2[:, -1] = {arr2[:, -1]}\")\n",
        "\n",
        "print(f\"\\nAdvanced 2D slicing:\")\n",
        "print(f\"2 h√†ng ƒë·∫ßu:\\n{arr2[:2, :]}\")\n",
        "print(f\"2 c·ªôt cu·ªëi:\\n{arr2[:, -2:]}\")\n",
        "print(f\"V√πng gi·ªØa (t·ª´ h√†ng 1, c·ªôt 1-3):\\n{arr2[1:, 1:4]}\")"
      ],
      "metadata": {
        "id": "indexing_2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Advanced Indexing\n",
        "print(f\"üî∏ Advanced Indexing:\")\n",
        "\n",
        "# Boolean indexing\n",
        "condition = arr > 5\n",
        "print(f\"\\nArray: {arr}\")\n",
        "print(f\"Condition (arr > 5): {condition}\")\n",
        "print(f\"Elements > 5: {arr[condition]}\")\n",
        "\n",
        "# Fancy indexing\n",
        "indices = [0, 2, 4]\n",
        "print(f\"\\nFancy indexing arr[{indices}]: {arr[indices]}\")\n",
        "\n",
        "# Where function\n",
        "result = np.where(arr > 5, arr, 0)  # If >5 keep, else 0\n",
        "print(f\"Where arr > 5: {result}\")\n",
        "\n",
        "# Multiple conditions\n",
        "multi_result = np.where((arr > 2) & (arr < 8), arr, -1)\n",
        "print(f\"Where 2 < arr < 8: {multi_result}\")\n",
        "\n",
        "# 2D boolean indexing\n",
        "print(f\"\\n2D Boolean indexing:\")\n",
        "condition_2d = arr2 > 5\n",
        "print(f\"Elements > 5 in 2D: {arr2[condition_2d]}\")"
      ],
      "metadata": {
        "id": "advanced_indexing"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IV. Bi·∫øn ƒë·ªïi m·∫£ng"
      ],
      "metadata": {
        "id": "array_transformation_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Bi·∫øn ƒë·ªïi ma tr·∫≠n\n",
        "print(\"üîÑ 4. BI·∫æN ƒê·ªîI M·∫¢NG\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Reshape\n",
        "print(\"üî∏ Reshape:\")\n",
        "arr = np.arange(1, 25)\n",
        "print(f\"Original array: {arr}\")\n",
        "print(f\"Shape: {arr.shape}\")\n",
        "\n",
        "# C√°c c√°ch reshape kh√°c nhau\n",
        "print(f\"\\nReshape examples:\")\n",
        "print(f\"(2, 12):\\n{arr.reshape(2, 12)}\")\n",
        "print(f\"\\n(3, 8):\\n{arr.reshape(3, 8)}\")\n",
        "print(f\"\\n(4, 6):\\n{arr.reshape(4, 6)}\")\n",
        "print(f\"\\n(4, 3, 2):\\n{arr.reshape(4, 3, 2)}\")\n",
        "\n",
        "# Auto reshape v·ªõi -1\n",
        "print(f\"\\nüî∏ Auto reshape v·ªõi -1:\")\n",
        "auto1 = arr.reshape(-1, 6)  # -1 t·ª± ƒë·ªông = 4\n",
        "auto2 = arr.reshape(3, -1)  # -1 t·ª± ƒë·ªông = 8\n",
        "print(f\"reshape(-1, 6): shape = {auto1.shape}\")\n",
        "print(f\"reshape(3, -1): shape = {auto2.shape}\")"
      ],
      "metadata": {
        "id": "reshape_operations"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transpose\n",
        "print(\"üî∏ Transpose:\")\n",
        "matrix = np.arange(1, 13).reshape(3, 4)\n",
        "print(f\"Original matrix (3x4):\\n{matrix}\")\n",
        "print(f\"\\nTransposed (4x3):\\n{matrix.T}\")\n",
        "print(f\"\\nUsing transpose():\\n{matrix.transpose()}\")\n",
        "\n",
        "# Flatten v√† ravel\n",
        "print(f\"\\nüî∏ Flatten vs Ravel:\")\n",
        "print(f\"Original matrix:\\n{matrix}\")\n",
        "\n",
        "flattened = matrix.flatten()  # T·∫°o copy\n",
        "raveled = matrix.ravel()      # T·∫°o view n·∫øu c√≥ th·ªÉ\n",
        "\n",
        "print(f\"Flattened: {flattened}\")\n",
        "print(f\"Raveled: {raveled}\")\n",
        "\n",
        "# Test s·ª± kh√°c bi·ªát\n",
        "matrix[0, 0] = 999\n",
        "print(f\"\\nSau khi thay ƒë·ªïi matrix[0,0] = 999:\")\n",
        "print(f\"Matrix:\\n{matrix}\")\n",
        "print(f\"Flattened: {flattened}\")  # Kh√¥ng ƒë·ªïi (copy)\n",
        "print(f\"Raveled: {raveled}\")      # C√≥ th·ªÉ ƒë·ªïi (view)\n",
        "\n",
        "# Reset matrix\n",
        "matrix = np.arange(1, 13).reshape(3, 4)"
      ],
      "metadata": {
        "id": "transpose_flatten"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## V. C√°c ph√©p to√°n v√† h√†m to√°n h·ªçc"
      ],
      "metadata": {
        "id": "math_operations_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. C√°c ph√©p to√°n v√† h√†m to√°n h·ªçc\n",
        "print(\"üßÆ 5. C√ÅC PH√âP TO√ÅN V√Ä H√ÄM TO√ÅN H·ªåC\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Element-wise operations\n",
        "print(\"üî∏ Element-wise operations:\")\n",
        "a = np.array([1, 2, 3, 4])\n",
        "b = np.array([5, 6, 7, 8])\n",
        "\n",
        "print(f\"a = {a}\")\n",
        "print(f\"b = {b}\")\n",
        "print(f\"a + b = {a + b}\")\n",
        "print(f\"a - b = {a - b}\")\n",
        "print(f\"a * b = {a * b}\")\n",
        "print(f\"a / b = {a / b}\")\n",
        "print(f\"a ** 2 = {a ** 2}\")\n",
        "print(f\"a % 3 = {a % 3}\")\n",
        "\n",
        "# Broadcasting\n",
        "print(f\"\\nüî∏ Broadcasting:\")\n",
        "matrix = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "vector = np.array([10, 20, 30])\n",
        "scalar = 100\n",
        "\n",
        "print(f\"Matrix (2x3):\\n{matrix}\")\n",
        "print(f\"Vector (3,): {vector}\")\n",
        "print(f\"Scalar: {scalar}\")\n",
        "\n",
        "print(f\"\\nMatrix + Vector:\\n{matrix + vector}\")\n",
        "print(f\"\\nMatrix + Scalar:\\n{matrix + scalar}\")\n",
        "print(f\"\\nMatrix * Vector:\\n{matrix * vector}\")"
      ],
      "metadata": {
        "id": "basic_math_operations"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mathematical functions\n",
        "print(f\"üî∏ Mathematical functions:\")\n",
        "arr = np.array([1, 4, 9, 16, 25])\n",
        "print(f\"Array: {arr}\")\n",
        "\n",
        "print(f\"\\nBasic math:\")\n",
        "print(f\"sqrt(arr) = {np.sqrt(arr)}\")\n",
        "print(f\"square(arr) = {np.square(arr)}\")\n",
        "print(f\"abs(arr) = {np.abs(arr)}\")\n",
        "\n",
        "print(f\"\\nTrigonometric:\")\n",
        "angles = np.array([0, np.pi/4, np.pi/2, np.pi])\n",
        "print(f\"angles = {angles}\")\n",
        "print(f\"sin(angles) = {np.sin(angles)}\")\n",
        "print(f\"cos(angles) = {np.cos(angles)}\")\n",
        "\n",
        "print(f\"\\nExponential and log:\")\n",
        "print(f\"exp(arr) = {np.exp(arr)}\")\n",
        "print(f\"log(arr) = {np.log(arr)}\")\n",
        "print(f\"log10(arr) = {np.log10(arr)}\")\n",
        "\n",
        "# Rounding functions\n",
        "float_arr = np.array([1.2, 2.7, -1.8, -2.3, 3.5])\n",
        "print(f\"\\nüî∏ Rounding functions:\")\n",
        "print(f\"Float array: {float_arr}\")\n",
        "print(f\"round: {np.round(float_arr)}\")\n",
        "print(f\"floor: {np.floor(float_arr)}\")\n",
        "print(f\"ceil: {np.ceil(float_arr)}\")"
      ],
      "metadata": {
        "id": "advanced_math_functions"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistical functions\n",
        "print(f\"üî∏ Statistical functions:\")\n",
        "data = np.random.normal(50, 10, 100)  # Normal distribution\n",
        "print(f\"Data sample (first 10): {data[:10]}\")\n",
        "\n",
        "print(f\"\\nBasic statistics:\")\n",
        "print(f\"Mean: {np.mean(data):.2f}\")\n",
        "print(f\"Median: {np.median(data):.2f}\")\n",
        "print(f\"Std: {np.std(data):.2f}\")\n",
        "print(f\"Var: {np.var(data):.2f}\")\n",
        "print(f\"Min: {np.min(data):.2f}\")\n",
        "print(f\"Max: {np.max(data):.2f}\")\n",
        "print(f\"Sum: {np.sum(data):.2f}\")\n",
        "\n",
        "# Percentiles\n",
        "print(f\"\\nPercentiles:\")\n",
        "print(f\"25th percentile: {np.percentile(data, 25):.2f}\")\n",
        "print(f\"50th percentile: {np.percentile(data, 50):.2f}\")\n",
        "print(f\"75th percentile: {np.percentile(data, 75):.2f}\")\n",
        "\n",
        "# Axis operations\n",
        "print(f\"\\nüî∏ Axis operations:\")\n",
        "matrix_2d = np.random.randint(1, 10, (3, 4))\n",
        "print(f\"Matrix (3x4):\\n{matrix_2d}\")\n",
        "print(f\"Sum axis=0 (columns): {np.sum(matrix_2d, axis=0)}\")\n",
        "print(f\"Sum axis=1 (rows): {np.sum(matrix_2d, axis=1)}\")\n",
        "print(f\"Mean axis=0: {np.mean(matrix_2d, axis=0)}\")\n",
        "print(f\"Max axis=1: {np.max(matrix_2d, axis=1)}\")"
      ],
      "metadata": {
        "id": "statistical_functions"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VI. Dot Product v√† Linear Algebra"
      ],
      "metadata": {
        "id": "linear_algebra_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Dot Product v√† Linear Algebra\n",
        "print(\"üéØ 6. DOT PRODUCT V√Ä LINEAR ALGEBRA\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Basic dot product\n",
        "print(\"üî∏ Vector dot product:\")\n",
        "v1 = np.array([1, 2, 3])\n",
        "v2 = np.array([4, 5, 6])\n",
        "\n",
        "dot_result = np.dot(v1, v2)\n",
        "print(f\"v1 = {v1}\")\n",
        "print(f\"v2 = {v2}\")\n",
        "print(f\"v1 ‚Ä¢ v2 = {dot_result}\")\n",
        "print(f\"Using @ operator: {v1 @ v2}\")\n",
        "print(f\"Manual calculation: {1*4 + 2*5 + 3*6} = {dot_result}\")\n",
        "\n",
        "# Matrix multiplication\n",
        "print(f\"\\nüî∏ Matrix multiplication:\")\n",
        "A = np.array([[1, 2], [3, 4]])  # 2x2\n",
        "B = np.array([[5, 6], [7, 8]])  # 2x2\n",
        "\n",
        "C = np.dot(A, B)\n",
        "print(f\"A (2x2):\\n{A}\")\n",
        "print(f\"B (2x2):\\n{B}\")\n",
        "print(f\"A @ B (2x2):\\n{C}\")\n",
        "\n",
        "# Matrix √ó Vector\n",
        "print(f\"\\nüî∏ Matrix √ó Vector:\")\n",
        "matrix = np.array([[1, 2, 3], [4, 5, 6]])  # 2x3\n",
        "vector = np.array([7, 8, 9])               # 3x1\n",
        "\n",
        "result = np.dot(matrix, vector)\n",
        "print(f\"Matrix (2x3):\\n{matrix}\")\n",
        "print(f\"Vector (3,): {vector}\")\n",
        "print(f\"Result (2,): {result}\")\n",
        "\n",
        "# Practical example: Weighted average\n",
        "print(f\"\\nüî∏ Practical example - Weighted scores:\")\n",
        "subjects = ['Math', 'Physics', 'Chemistry', 'Biology']\n",
        "scores = np.array([85, 90, 78, 92])\n",
        "weights = np.array([0.3, 0.3, 0.2, 0.2])\n",
        "\n",
        "weighted_avg = np.dot(scores, weights)\n",
        "print(f\"Subjects: {subjects}\")\n",
        "print(f\"Scores: {scores}\")\n",
        "print(f\"Weights: {weights}\")\n",
        "print(f\"Weighted average: {weighted_avg:.2f}\")\n",
        "\n",
        "# Revenue calculation\n",
        "print(f\"\\nüî∏ Business example - Revenue calculation:\")\n",
        "products = ['Product A', 'Product B', 'Product C']\n",
        "quantities = np.array([10, 5, 8])\n",
        "prices = np.array([100, 200, 150])\n",
        "\n",
        "total_revenue = np.dot(quantities, prices)\n",
        "print(f\"Products: {products}\")\n",
        "print(f\"Quantities sold: {quantities}\")\n",
        "print(f\"Prices: {prices}\")\n",
        "print(f\"Total revenue: ${total_revenue:,}\")"
      ],
      "metadata": {
        "id": "dot_product_examples"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# üêº **PH·∫¶N 2: PANDAS - PANEL DATA**\n",
        "\n",
        "Pandas cung c·∫•p c·∫•u tr√∫c d·ªØ li·ªáu v√† c√¥ng c·ª• ph√¢n t√≠ch d·ªØ li·ªáu m·∫°nh m·∫Ω:\n",
        "- üìä **Series**: m·∫£ng 1 chi·ªÅu c√≥ nh√£n\n",
        "- üìã **DataFrame**: b·∫£ng d·ªØ li·ªáu 2 chi·ªÅu\n",
        "- üîß **C√¥ng c·ª•**: x·ª≠ l√Ω d·ªØ li·ªáu thi·∫øu, merge, group by"
      ],
      "metadata": {
        "id": "pandas_section_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Pandas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print(f\"üìã Pandas version: {pd.__version__}\")\n",
        "print(\"üêº Ready to work with data!\")"
      ],
      "metadata": {
        "id": "pandas_import"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## I. Pandas Series"
      ],
      "metadata": {
        "id": "pandas_series_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Pandas Series\n",
        "print(\"üìä 1. PANDAS SERIES\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "# T·∫°o Series c∆° b·∫£n\n",
        "print(\"üî∏ T·∫°o Series:\")\n",
        "s1 = pd.Series([1, 3, 5, 7, 9])\n",
        "print(f\"Series c∆° b·∫£n:\\n{s1}\")\n",
        "\n",
        "# Series v·ªõi index t√πy ch·ªânh\n",
        "s2 = pd.Series([100, 200, 300], index=['A', 'B', 'C'])\n",
        "print(f\"\\nSeries v·ªõi custom index:\\n{s2}\")\n",
        "\n",
        "# Series t·ª´ dictionary\n",
        "data_dict = {'Apple': 150, 'Banana': 80, 'Orange': 120, 'Mango': 200}\n",
        "s3 = pd.Series(data_dict)\n",
        "print(f\"\\nSeries t·ª´ dictionary:\\n{s3}\")\n",
        "\n",
        "# Series t·ª´ numpy array\n",
        "np_arr = np.random.randint(50, 100, 5)\n",
        "s4 = pd.Series(np_arr, index=['Mon', 'Tue', 'Wed', 'Thu', 'Fri'])\n",
        "print(f\"\\nSeries t·ª´ numpy (ƒëi·ªÉm s·ªë tu·∫ßn):\\n{s4}\")\n",
        "\n",
        "print(f\"\\nüî∏ Thu·ªôc t√≠nh Series:\")\n",
        "print(f\"Values: {s3.values}\")\n",
        "print(f\"Index: {s3.index.tolist()}\")\n",
        "print(f\"Data type: {s3.dtype}\")\n",
        "print(f\"Size: {s3.size}\")\n",
        "print(f\"Shape: {s3.shape}\")"
      ],
      "metadata": {
        "id": "pandas_series_creation"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Truy xu·∫•t d·ªØ li·ªáu Series\n",
        "print(\"üî∏ Truy xu·∫•t d·ªØ li·ªáu Series:\")\n",
        "print(f\"Series: {s3}\")\n",
        "\n",
        "# Label-based indexing\n",
        "print(f\"\\nLabel-based indexing:\")\n",
        "print(f\"s3['Apple'] = {s3['Apple']}\")\n",
        "print(f\"s3[['Apple', 'Mango']] = \\n{s3[['Apple', 'Mango']]}\")\n",
        "\n",
        "# Position-based indexing\n",
        "print(f\"\\nPosition-based indexing:\")\n",
        "print(f\"s3.iloc[0] = {s3.iloc[0]}\")\n",
        "print(f\"s3.iloc[1:3] = \\n{s3.iloc[1:3]}\")\n",
        "\n",
        "# Boolean indexing\n",
        "print(f\"\\nBoolean indexing:\")\n",
        "expensive = s3 > 100\n",
        "print(f\"Expensive fruits (>100): \\n{s3[expensive]}\")\n",
        "\n",
        "# Operations on Series\n",
        "print(f\"\\nüî∏ Operations on Series:\")\n",
        "print(f\"Original prices:\\n{s3}\")\n",
        "print(f\"\\nPrice * 1.1 (10% increase):\\n{s3 * 1.1}\")\n",
        "print(f\"\\nPrice + 20 (add 20):\\n{s3 + 20}\")\n",
        "print(f\"\\nMath operations:\")\n",
        "print(f\"Sum: {s3.sum()}\")\n",
        "print(f\"Mean: {s3.mean():.2f}\")\n",
        "print(f\"Max: {s3.max()}\")\n",
        "print(f\"Min: {s3.min()}\")\n",
        "print(f\"Std: {s3.std():.2f}\")"
      ],
      "metadata": {
        "id": "series_operations"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## II. Pandas DataFrame"
      ],
      "metadata": {
        "id": "dataframe_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Pandas DataFrame\n",
        "print(\"üìã 2. PANDAS DATAFRAME\")\n",
        "print(\"=\" * 35)\n",
        "\n",
        "# T·∫°o DataFrame t·ª´ dictionary\n",
        "print(\"üî∏ T·∫°o DataFrame t·ª´ dictionary:\")\n",
        "data = {\n",
        "    'T√™n': ['An', 'B√¨nh', 'Chi', 'Dung', 'Em', 'Phong'],\n",
        "    'Tu·ªïi': [25, 30, 35, 28, 22, 27],\n",
        "    'L∆∞∆°ng': [5000, 6000, 7000, 5500, 4500, 5800],\n",
        "    'Th√†nh ph·ªë': ['H√† N·ªôi', 'HCM', 'ƒê√† N·∫µng', 'H√† N·ªôi', 'HCM', 'C·∫ßn Th∆°'],\n",
        "    'Kinh nghi·ªám': [2, 5, 8, 4, 1, 3]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(\"DataFrame nh√¢n vi√™n:\")\n",
        "print(df)\n",
        "\n",
        "# T·∫°o DataFrame t·ª´ list of lists\n",
        "print(f\"\\nüî∏ DataFrame t·ª´ list of lists:\")\n",
        "data_list = [\n",
        "    ['Product A', 100, 'Electronics'],\n",
        "    ['Product B', 150, 'Clothing'],\n",
        "    ['Product C', 80, 'Books'],\n",
        "    ['Product D', 200, 'Electronics']\n",
        "]\n",
        "df_products = pd.DataFrame(data_list, columns=['Product', 'Price', 'Category'])\n",
        "print(\"DataFrame s·∫£n ph·∫©m:\")\n",
        "print(df_products)\n",
        "\n",
        "# Th√¥ng tin c∆° b·∫£n v·ªÅ DataFrame\n",
        "print(f\"\\nüî∏ Th√¥ng tin c∆° b·∫£n v·ªÅ DataFrame:\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n",
        "print(f\"Index: {list(df.index)}\")\n",
        "print(f\"Size: {df.size}\")\n",
        "print(f\"\\nData types:\\n{df.dtypes}\")"
      ],
      "metadata": {
        "id": "dataframe_creation"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Xem v√† kh√°m ph√° d·ªØ li·ªáu\n",
        "print(\"üî∏ Xem v√† kh√°m ph√° d·ªØ li·ªáu:\")\n",
        "\n",
        "print(\"Head (3 d√≤ng ƒë·∫ßu):\")\n",
        "print(df.head(3))\n",
        "\n",
        "print(\"\\nTail (3 d√≤ng cu·ªëi):\")\n",
        "print(df.tail(3))\n",
        "\n",
        "print(\"\\nInfo (th√¥ng tin t·ªïng quan):\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\nDescribe (th·ªëng k√™ m√¥ t·∫£ cho c·ªôt s·ªë):\")\n",
        "print(df.describe())\n",
        "\n",
        "print(\"\\nDescribe cho t·∫•t c·∫£ c·ªôt:\")\n",
        "print(df.describe(include='all'))"
      ],
      "metadata": {
        "id": "dataframe_exploration"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Truy xu·∫•t d·ªØ li·ªáu DataFrame\n",
        "print(\"üî∏ Truy xu·∫•t d·ªØ li·ªáu DataFrame:\")\n",
        "\n",
        "# Truy xu·∫•t c·ªôt\n",
        "print(\"Truy xu·∫•t c·ªôt 'T√™n':\")\n",
        "print(df['T√™n'])\n",
        "print(f\"Type: {type(df['T√™n'])}\")\n",
        "\n",
        "print(\"\\nTruy xu·∫•t nhi·ªÅu c·ªôt:\")\n",
        "print(df[['T√™n', 'L∆∞∆°ng', 'Th√†nh ph·ªë']])\n",
        "\n",
        "# Truy xu·∫•t h√†ng\n",
        "print(\"\\nüî∏ Truy xu·∫•t h√†ng:\")\n",
        "print(\"H√†ng ƒë·∫ßu ti√™n (iloc - position):\")\n",
        "print(df.iloc[0])\n",
        "\n",
        "print(\"\\nH√†ng ƒë·∫ßu ti√™n (loc - label):\")\n",
        "print(df.loc[0])\n",
        "\n",
        "print(\"\\nNhi·ªÅu h√†ng (iloc):\")\n",
        "print(df.iloc[1:4])\n",
        "\n",
        "print(\"\\nNhi·ªÅu h√†ng (loc):\")\n",
        "print(df.loc[1:3])  # Inclusive end v·ªõi loc\n",
        "\n",
        "# Truy xu·∫•t √¥ c·ª• th·ªÉ\n",
        "print(f\"\\nüî∏ Truy xu·∫•t √¥ c·ª• th·ªÉ:\")\n",
        "print(f\"df.iloc[0, 1] (h√†ng 0, c·ªôt 1): {df.iloc[0, 1]}\")\n",
        "print(f\"df.loc[0, 'Tu·ªïi'] (h√†ng 0, c·ªôt 'Tu·ªïi'): {df.loc[0, 'Tu·ªïi']}\")\n",
        "print(f\"df.at[0, 'T√™n'] (nhanh nh·∫•t cho 1 √¥): {df.at[0, 'T√™n']}\")\n",
        "\n",
        "# Truy xu·∫•t v·ªõi ƒëi·ªÅu ki·ªán\n",
        "print(f\"\\nüî∏ Slice v·ªõi ƒëi·ªÅu ki·ªán:\")\n",
        "print(\"L·∫•y t√™n v√† l∆∞∆°ng c·ªßa 3 ng∆∞·ªùi ƒë·∫ßu:\")\n",
        "print(df.loc[0:2, ['T√™n', 'L∆∞∆°ng']])"
      ],
      "metadata": {
        "id": "dataframe_access"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## III. L·ªçc v√† t√¨m ki·∫øm d·ªØ li·ªáu"
      ],
      "metadata": {
        "id": "filtering_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. L·ªçc v√† t√¨m ki·∫øm d·ªØ li·ªáu\n",
        "print(\"üîç 3. L·ªåC V√Ä T√åM KI·∫æM D·ªÆ LI·ªÜU\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "print(\"DataFrame g·ªëc:\")\n",
        "print(df)\n",
        "\n",
        "# L·ªçc theo ƒëi·ªÅu ki·ªán ƒë∆°n\n",
        "print(\"\\nüî∏ L·ªçc theo ƒëi·ªÅu ki·ªán ƒë∆°n:\")\n",
        "high_salary = df[df['L∆∞∆°ng'] > 5500]\n",
        "print(\"Ng∆∞·ªùi c√≥ l∆∞∆°ng > 5500:\")\n",
        "print(high_salary)\n",
        "\n",
        "young_people = df[df['Tu·ªïi'] < 30]\n",
        "print(\"\\nNg∆∞·ªùi tr·∫ª (<30 tu·ªïi):\")\n",
        "print(young_people[['T√™n', 'Tu·ªïi', 'L∆∞∆°ng']])\n",
        "\n",
        "# L·ªçc theo nhi·ªÅu ƒëi·ªÅu ki·ªán\n",
        "print(\"\\nüî∏ L·ªçc theo nhi·ªÅu ƒëi·ªÅu ki·ªán:\")\n",
        "young_high_salary = df[(df['Tu·ªïi'] < 30) & (df['L∆∞∆°ng'] > 5000)]\n",
        "print(\"Tu·ªïi < 30 V√Ä l∆∞∆°ng > 5000:\")\n",
        "print(young_high_salary[['T√™n', 'Tu·ªïi', 'L∆∞∆°ng']])\n",
        "\n",
        "experienced_or_young = df[(df['Kinh nghi·ªám'] >= 5) | (df['Tu·ªïi'] <= 25)]\n",
        "print(\"\\nKinh nghi·ªám ‚â• 5 HO·∫∂C tu·ªïi ‚â§ 25:\")\n",
        "print(experienced_or_young[['T√™n', 'Tu·ªïi', 'Kinh nghi·ªám']])\n",
        "\n",
        "# L·ªçc theo string\n",
        "print(\"\\nüî∏ L·ªçc theo string:\")\n",
        "hanoi_people = df[df['Th√†nh ph·ªë'] == 'H√† N·ªôi']\n",
        "print(\"Ng∆∞·ªùi ·ªü H√† N·ªôi:\")\n",
        "print(hanoi_people[['T√™n', 'Th√†nh ph·ªë', 'L∆∞∆°ng']])\n",
        "\n",
        "# Contains string\n",
        "name_with_n = df[df['T√™n'].str.contains('n', case=False)]\n",
        "print(\"\\nT√™n ch·ª©a ch·ªØ 'n':\")\n",
        "print(name_with_n[['T√™n']])"
      ],
      "metadata": {
        "id": "basic_filtering"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# L·ªçc n√¢ng cao\n",
        "print(\"üî∏ L·ªçc n√¢ng cao:\")\n",
        "\n",
        "# L·ªçc theo danh s√°ch\n",
        "selected_cities = df[df['Th√†nh ph·ªë'].isin(['H√† N·ªôi', 'HCM'])]\n",
        "print(\"Ng∆∞·ªùi ·ªü H√† N·ªôi ho·∫∑c HCM:\")\n",
        "print(selected_cities[['T√™n', 'Th√†nh ph·ªë']])\n",
        "\n",
        "# L·ªçc theo range\n",
        "mid_range_salary = df[df['L∆∞∆°ng'].between(5000, 6000)]\n",
        "print(\"\\nL∆∞∆°ng t·ª´ 5000-6000:\")\n",
        "print(mid_range_salary[['T√™n', 'L∆∞∆°ng']])\n",
        "\n",
        "# Query method (SQL-like)\n",
        "print(\"\\nüî∏ S·ª≠ d·ª•ng query() method:\")\n",
        "result1 = df.query('Tu·ªïi >= 28 and L∆∞∆°ng <= 6000')\n",
        "print(\"Query: 'Tu·ªïi >= 28 and L∆∞∆°ng <= 6000'\")\n",
        "print(result1[['T√™n', 'Tu·ªïi', 'L∆∞∆°ng']])\n",
        "\n",
        "result2 = df.query('Th√†nh_ph·ªë == \"H√† N·ªôi\" and Kinh_nghi·ªám > 2')\n",
        "print(\"\\nQuery: 'Th√†nh_ph·ªë == \"H√† N·ªôi\" and Kinh_nghi·ªám > 2'\")\n",
        "print(result2[['T√™n', 'Th√†nh ph·ªë', 'Kinh nghi·ªám']])\n",
        "\n",
        "# Negate conditions\n",
        "print(\"\\nüî∏ ƒêi·ªÅu ki·ªán ph·ªß ƒë·ªãnh:\")\n",
        "not_hanoi = df[~(df['Th√†nh ph·ªë'] == 'H√† N·ªôi')]\n",
        "print(\"Kh√¥ng ·ªü H√† N·ªôi:\")\n",
        "print(not_hanoi[['T√™n', 'Th√†nh ph·ªë']])\n",
        "\n",
        "# Top/Bottom records\n",
        "print(\"\\nüî∏ Top/Bottom records:\")\n",
        "top_salary = df.nlargest(3, 'L∆∞∆°ng')\n",
        "print(\"Top 3 l∆∞∆°ng cao nh·∫•t:\")\n",
        "print(top_salary[['T√™n', 'L∆∞∆°ng']])\n",
        "\n",
        "youngest = df.nsmallest(2, 'Tu·ªïi')\n",
        "print(\"\\n2 ng∆∞·ªùi tr·∫ª nh·∫•t:\")\n",
        "print(youngest[['T√™n', 'Tu·ªïi']])"
      ],
      "metadata": {
        "id": "advanced_filtering"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IV. Th√™m, s·ª≠a, x√≥a d·ªØ li·ªáu"
      ],
      "metadata": {
        "id": "data_manipulation_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Th√™m, s·ª≠a, x√≥a d·ªØ li·ªáu\n",
        "print(\"‚ûï 4. TH√äM, S·ª¨A, X√ìA D·ªÆ LI·ªÜU\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# T·∫°o copy ƒë·ªÉ kh√¥ng ·∫£nh h∆∞·ªüng df g·ªëc\n",
        "df_work = df.copy()\n",
        "\n",
        "# Th√™m c·ªôt m·ªõi\n",
        "print(\"üî∏ Th√™m c·ªôt m·ªõi:\")\n",
        "print(\"DataFrame g·ªëc:\")\n",
        "print(df_work[['T√™n', 'L∆∞∆°ng']])\n",
        "\n",
        "# Th√™m c·ªôt t√≠nh to√°n\n",
        "df_work['Th∆∞·ªüng'] = df_work['L∆∞∆°ng'] * 0.1\n",
        "df_work['T·ªïng_thu_nh·∫≠p'] = df_work['L∆∞∆°ng'] + df_work['Th∆∞·ªüng']\n",
        "\n",
        "# Th√™m c·ªôt ƒëi·ªÅu ki·ªán\n",
        "df_work['C·∫•p_ƒë·ªô'] = df_work['Tu·ªïi'].apply(lambda x: 'Senior' if x >= 30 else 'Junior')\n",
        "\n",
        "# Th√™m c·ªôt v·ªõi multiple conditions\n",
        "def classify_employee(row):\n",
        "    if row['Kinh nghi·ªám'] >= 5:\n",
        "        return 'Expert'\n",
        "    elif row['Kinh nghi·ªám'] >= 3:\n",
        "        return 'Experienced'\n",
        "    else:\n",
        "        return 'Beginner'\n",
        "\n",
        "df_work['Ph√¢n_lo·∫°i'] = df_work.apply(classify_employee, axis=1)\n",
        "\n",
        "print(\"\\nSau khi th√™m c·ªôt:\")\n",
        "print(df_work[['T√™n', 'L∆∞∆°ng', 'Th∆∞·ªüng', 'T·ªïng_thu_nh·∫≠p', 'C·∫•p_ƒë·ªô', 'Ph√¢n_lo·∫°i']])\n",
        "\n",
        "# Th√™m h√†ng m·ªõi\n",
        "print(\"\\nüî∏ Th√™m h√†ng m·ªõi:\")\n",
        "new_employees = [\n",
        "    {'T√™n': 'Giang', 'Tu·ªïi': 26, 'L∆∞∆°ng': 5200, 'Th√†nh ph·ªë': 'H√† N·ªôi', 'Kinh nghi·ªám': 2},\n",
        "    {'T√™n': 'Ho√†ng', 'Tu·ªïi': 32, 'L∆∞∆°ng': 6500, 'Th√†nh ph·ªë': 'HCM', 'Kinh nghi·ªám': 6}\n",
        "]\n",
        "\n",
        "df_new = pd.concat([df, pd.DataFrame(new_employees)], ignore_index=True)\n",
        "print(\"DataFrame sau khi th√™m 2 nh√¢n vi√™n m·ªõi:\")\n",
        "print(df_new.tail(4))  # Show last 4 rows"
      ],
      "metadata": {
        "id": "add_columns_rows"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# S·ª≠a d·ªØ li·ªáu\n",
        "print(\"üî∏ S·ª≠a d·ªØ li·ªáu:\")\n",
        "df_edit = df.copy()\n",
        "\n",
        "print(\"Tr∆∞·ªõc khi s·ª≠a:\")\n",
        "print(df_edit.loc[0, ['T√™n', 'L∆∞∆°ng']])\n",
        "\n",
        "# S·ª≠a 1 √¥\n",
        "df_edit.loc[0, 'L∆∞∆°ng'] = 5200\n",
        "print(f\"\\nSau khi s·ª≠a l∆∞∆°ng An th√†nh 5200:\")\n",
        "print(df_edit.loc[0, ['T√™n', 'L∆∞∆°ng']])\n",
        "\n",
        "# S·ª≠a nhi·ªÅu √¥\n",
        "df_edit.loc[df_edit['T√™n'] == 'B√¨nh', ['L∆∞∆°ng', 'Tu·ªïi']] = [6200, 31]\n",
        "print(f\"\\nSau khi s·ª≠a th√¥ng tin B√¨nh:\")\n",
        "print(df_edit[df_edit['T√™n'] == 'B√¨nh'][['T√™n', 'Tu·ªïi', 'L∆∞∆°ng']])\n",
        "\n",
        "# S·ª≠a c·∫£ c·ªôt\n",
        "print(f\"\\nTr∆∞·ªõc khi tƒÉng tu·ªïi:\")\n",
        "print(df_edit[['T√™n', 'Tu·ªïi']])\n",
        "\n",
        "df_edit['Tu·ªïi'] = df_edit['Tu·ªïi'] + 1  # TƒÉng tu·ªïi 1\n",
        "print(f\"\\nSau khi tƒÉng tu·ªïi to√†n b·ªô:\")\n",
        "print(df_edit[['T√™n', 'Tu·ªïi']])\n",
        "\n",
        "# S·ª≠a theo ƒëi·ªÅu ki·ªán\n",
        "print(f\"\\nTr∆∞·ªõc khi tƒÉng l∆∞∆°ng cho ng∆∞·ªùi l∆∞∆°ng th·∫•p:\")\n",
        "low_salary_before = df_edit[df_edit['L∆∞∆°ng'] < 5500][['T√™n', 'L∆∞∆°ng']]\n",
        "print(low_salary_before)\n",
        "\n",
        "df_edit.loc[df_edit['L∆∞∆°ng'] < 5500, 'L∆∞∆°ng'] *= 1.1  # TƒÉng 10%\n",
        "print(f\"\\nSau khi tƒÉng l∆∞∆°ng 10% cho ng∆∞·ªùi c√≥ l∆∞∆°ng < 5500:\")\n",
        "updated_salaries = df_edit[df_edit.index.isin(low_salary_before.index)][['T√™n', 'L∆∞∆°ng']]\n",
        "print(updated_salaries)"
      ],
      "metadata": {
        "id": "edit_data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X√≥a d·ªØ li·ªáu\n",
        "print(\"üî∏ X√≥a d·ªØ li·ªáu:\")\n",
        "df_delete = df.copy()\n",
        "\n",
        "print(\"DataFrame g·ªëc:\")\n",
        "print(df_delete.columns.tolist())\n",
        "print(f\"Shape: {df_delete.shape}\")\n",
        "\n",
        "# X√≥a c·ªôt\n",
        "df_dropped_col = df_delete.drop('Th√†nh ph·ªë', axis=1)\n",
        "print(f\"\\nSau khi x√≥a c·ªôt 'Th√†nh ph·ªë':\")\n",
        "print(df_dropped_col.columns.tolist())\n",
        "print(f\"Shape: {df_dropped_col.shape}\")\n",
        "\n",
        "# X√≥a nhi·ªÅu c·ªôt\n",
        "df_dropped_cols = df_delete.drop(['Th√†nh ph·ªë', 'Kinh nghi·ªám'], axis=1)\n",
        "print(f\"\\nSau khi x√≥a 2 c·ªôt:\")\n",
        "print(df_dropped_cols.columns.tolist())\n",
        "\n",
        "# X√≥a h√†ng\n",
        "print(f\"\\nTr∆∞·ªõc khi x√≥a h√†ng:\")\n",
        "print(df_delete[['T√™n', 'Tu·ªïi']])\n",
        "\n",
        "df_dropped_row = df_delete.drop(0, axis=0)  # X√≥a h√†ng index 0\n",
        "print(f\"\\nSau khi x√≥a h√†ng ƒë·∫ßu ti√™n (An):\")\n",
        "print(df_dropped_row[['T√™n', 'Tu·ªïi']])\n",
        "\n",
        "# X√≥a nhi·ªÅu h√†ng\n",
        "df_dropped_rows = df_delete.drop([0, 2], axis=0)  # X√≥a An v√† Chi\n",
        "print(f\"\\nSau khi x√≥a h√†ng 0 v√† 2 (An v√† Chi):\")\n",
        "print(df_dropped_rows[['T√™n', 'Tu·ªïi']])\n",
        "\n",
        "# X√≥a theo ƒëi·ªÅu ki·ªán\n",
        "df_conditional_drop = df_delete[df_delete['Tu·ªïi'] >= 25]  # Gi·ªØ l·∫°i ng∆∞·ªùi >= 25 tu·ªïi\n",
        "print(f\"\\nSau khi x√≥a ng∆∞·ªùi < 25 tu·ªïi:\")\n",
        "print(df_conditional_drop[['T√™n', 'Tu·ªïi']])\n",
        "\n",
        "# Reset index sau khi x√≥a\n",
        "df_reset = df_dropped_rows.reset_index(drop=True)\n",
        "print(f\"\\nSau khi reset index:\")\n",
        "print(df_reset[['T√™n', 'Tu·ªïi']])"
      ],
      "metadata": {
        "id": "delete_data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## V. X·ª≠ l√Ω d·ªØ li·ªáu thi·∫øu"
      ],
      "metadata": {
        "id": "missing_data_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. X·ª≠ l√Ω d·ªØ li·ªáu thi·∫øu (Missing Data)\n",
        "print(\"üîß 5. X·ª¨ L√ù D·ªÆ LI·ªÜU THI·∫æU\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# T·∫°o d·ªØ li·ªáu c√≥ gi√° tr·ªã thi·∫øu\n",
        "print(\"üî∏ T·∫°o d·ªØ li·ªáu thi·∫øu:\")\n",
        "df_missing = df.copy()\n",
        "\n",
        "# Th√™m m·ªôt s·ªë gi√° tr·ªã NaN\n",
        "df_missing.loc[1, 'L∆∞∆°ng'] = np.nan\n",
        "df_missing.loc[3, 'Tu·ªïi'] = np.nan\n",
        "df_missing.loc[4, 'Th√†nh ph·ªë'] = np.nan\n",
        "df_missing.loc[2, 'Kinh nghi·ªám'] = np.nan\n",
        "df_missing.loc[5, 'L∆∞∆°ng'] = np.nan\n",
        "\n",
        "print(\"DataFrame v·ªõi d·ªØ li·ªáu thi·∫øu:\")\n",
        "print(df_missing)\n",
        "\n",
        "# Ki·ªÉm tra d·ªØ li·ªáu thi·∫øu\n",
        "print(\"\\nüî∏ Ki·ªÉm tra d·ªØ li·ªáu thi·∫øu:\")\n",
        "print(\"S·ªë gi√° tr·ªã thi·∫øu m·ªói c·ªôt:\")\n",
        "missing_count = df_missing.isnull().sum()\n",
        "print(missing_count)\n",
        "\n",
        "print(\"\\nPh·∫ßn trƒÉm gi√° tr·ªã thi·∫øu:\")\n",
        "missing_percent = (df_missing.isnull().sum() / len(df_missing) * 100).round(2)\n",
        "print(missing_percent)\n",
        "\n",
        "# T·ªïng h·ª£p th√¥ng tin missing data\n",
        "missing_info = pd.DataFrame({\n",
        "    'Missing_Count': missing_count,\n",
        "    'Missing_Percent': missing_percent\n",
        "})\n",
        "print(\"\\nT·ªïng h·ª£p missing data:\")\n",
        "print(missing_info[missing_info['Missing_Count'] > 0])\n",
        "\n",
        "# Ki·ªÉm tra h√†ng n√†o c√≥ d·ªØ li·ªáu thi·∫øu\n",
        "print(\"\\nH√†ng c√≥ d·ªØ li·ªáu thi·∫øu:\")\n",
        "rows_with_missing = df_missing[df_missing.isnull().any(axis=1)]\n",
        "print(rows_with_missing)"
      ],
      "metadata": {
        "id": "missing_data_detection"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X·ª≠ l√Ω d·ªØ li·ªáu thi·∫øu - c√°c ph∆∞∆°ng ph√°p kh√°c nhau\n",
        "print(\"üî∏ C√°c ph∆∞∆°ng ph√°p x·ª≠ l√Ω d·ªØ li·ªáu thi·∫øu:\")\n",
        "\n",
        "# Ph∆∞∆°ng ph√°p 1: ƒêi·ªÅn gi√° tr·ªã c·ªë ƒë·ªãnh\n",
        "print(\"\\n1. ƒêi·ªÅn gi√° tr·ªã c·ªë ƒë·ªãnh:\")\n",
        "df_filled_0 = df_missing.fillna(0)\n",
        "print(\"ƒêi·ªÅn 0 cho t·∫•t c·∫£ NaN:\")\n",
        "print(df_filled_0[['T√™n', 'Tu·ªïi', 'L∆∞∆°ng', 'Th√†nh ph·ªë', 'Kinh nghi·ªám']])\n",
        "\n",
        "# Ph∆∞∆°ng ph√°p 2: ƒêi·ªÅn gi√° tr·ªã theo c·ªôt\n",
        "print(\"\\n2. ƒêi·ªÅn gi√° tr·ªã kh√°c nhau cho t·ª´ng c·ªôt:\")\n",
        "df_filled_custom = df_missing.copy()\n",
        "df_filled_custom['Tu·ªïi'].fillna(df_filled_custom['Tu·ªïi'].mean(), inplace=True)\n",
        "df_filled_custom['L∆∞∆°ng'].fillna(df_filled_custom['L∆∞∆°ng'].median(), inplace=True)\n",
        "df_filled_custom['Kinh nghi·ªám'].fillna(df_filled_custom['Kinh nghi·ªám'].mean(), inplace=True)\n",
        "df_filled_custom['Th√†nh ph·ªë'].fillna('Unknown', inplace=True)\n",
        "\n",
        "print(\"ƒêi·ªÅn mean/median cho s·ªë, 'Unknown' cho text:\")\n",
        "print(df_filled_custom)\n",
        "\n",
        "# Ph∆∞∆°ng ph√°p 3: Forward fill v√† backward fill\n",
        "print(\"\\n3. Forward fill v√† backward fill:\")\n",
        "df_ffill = df_missing.fillna(method='ffill')  # ƒêi·ªÅn gi√° tr·ªã t·ª´ tr∆∞·ªõc\n",
        "print(\"Forward fill (ffill):\")\n",
        "print(df_ffill[['T√™n', 'Tu·ªïi', 'L∆∞∆°ng']])\n",
        "\n",
        "df_bfill = df_missing.fillna(method='bfill')  # ƒêi·ªÅn gi√° tr·ªã t·ª´ sau\n",
        "print(\"\\nBackward fill (bfill):\")\n",
        "print(df_bfill[['T√™n', 'Tu·ªïi', 'L∆∞∆°ng']])\n",
        "\n",
        "# Ph∆∞∆°ng ph√°p 4: Interpolation\n",
        "print(\"\\n4. Interpolation (cho c·ªôt s·ªë):\")\n",
        "df_interpolated = df_missing.copy()\n",
        "df_interpolated['L∆∞∆°ng'] = df_interpolated['L∆∞∆°ng'].interpolate()\n",
        "df_interpolated['Tu·ªïi'] = df_interpolated['Tu·ªïi'].interpolate()\n",
        "print(\"Interpolated values:\")\n",
        "print(df_interpolated[['T√™n', 'Tu·ªïi', 'L∆∞∆°ng']])"
      ],
      "metadata": {
        "id": "missing_data_handling"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X√≥a d·ªØ li·ªáu thi·∫øu\n",
        "print(\"\\n5. X√≥a d·ªØ li·ªáu thi·∫øu:\")\n",
        "\n",
        "# X√≥a t·∫•t c·∫£ h√†ng c√≥ NaN\n",
        "df_dropped_any = df_missing.dropna()\n",
        "print(f\"X√≥a t·∫•t c·∫£ h√†ng c√≥ NaN:\")\n",
        "print(f\"Shape tr∆∞·ªõc: {df_missing.shape}\")\n",
        "print(f\"Shape sau: {df_dropped_any.shape}\")\n",
        "print(df_dropped_any)\n",
        "\n",
        "# X√≥a h√†ng c√≥ t·∫•t c·∫£ NaN\n",
        "df_dropped_all = df_missing.dropna(how='all')\n",
        "print(f\"\\nX√≥a h√†ng c√≥ t·∫•t c·∫£ NaN:\")\n",
        "print(f\"Shape: {df_dropped_all.shape}\")\n",
        "\n",
        "# X√≥a h√†ng c√≥ NaN trong c·ªôt c·ª• th·ªÉ\n",
        "df_dropped_subset = df_missing.dropna(subset=['L∆∞∆°ng'])\n",
        "print(f\"\\nX√≥a h√†ng c√≥ NaN trong c·ªôt 'L∆∞∆°ng':\")\n",
        "print(f\"Shape: {df_dropped_subset.shape}\")\n",
        "print(df_dropped_subset[['T√™n', 'L∆∞∆°ng']])\n",
        "\n",
        "# X√≥a c·ªôt c√≥ qu√° nhi·ªÅu NaN\n",
        "threshold = len(df_missing) * 0.5  # Gi·ªØ c·ªôt c√≥ √≠t h∆°n 50% NaN\n",
        "df_dropped_cols = df_missing.dropna(thresh=threshold, axis=1)\n",
        "print(f\"\\nX√≥a c·ªôt c√≥ >50% NaN:\")\n",
        "print(f\"Columns: {df_dropped_cols.columns.tolist()}\")\n",
        "\n",
        "# Ph∆∞∆°ng ph√°p 6: Advanced filling\n",
        "print(\"\\n6. Advanced filling strategies:\")\n",
        "df_advanced = df_missing.copy()\n",
        "\n",
        "# ƒêi·ªÅn based tr√™n group\n",
        "df_advanced['L∆∞∆°ng'] = df_advanced.groupby('Th√†nh ph·ªë')['L∆∞∆°ng'].transform(\n",
        "    lambda x: x.fillna(x.mean())\n",
        ")\n",
        "\n",
        "print(\"ƒêi·ªÅn l∆∞∆°ng theo mean c·ªßa t·ª´ng th√†nh ph·ªë:\")\n",
        "print(df_advanced[['T√™n', 'Th√†nh ph·ªë', 'L∆∞∆°ng']])\n",
        "\n",
        "# So s√°nh c√°c ph∆∞∆°ng ph√°p\n",
        "print(\"\\nüìä So s√°nh c√°c ph∆∞∆°ng ph√°p:\")\n",
        "methods_comparison = pd.DataFrame({\n",
        "    'Method': ['Original', 'Fill 0', 'Fill Mean/Median', 'Drop NaN', 'Interpolate'],\n",
        "    'Shape': [df_missing.shape, df_filled_0.shape, df_filled_custom.shape,\n",
        "              df_dropped_any.shape, df_interpolated.shape],\n",
        "    'Missing_Count': [df_missing.isnull().sum().sum(), df_filled_0.isnull().sum().sum(),\n",
        "                     df_filled_custom.isnull().sum().sum(), df_dropped_any.isnull().sum().sum(),\n",
        "                     df_interpolated.isnull().sum().sum()]\n",
        "})\n",
        "print(methods_comparison)"
      ],
      "metadata": {
        "id": "missing_data_strategies"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VI. Th·ªëng k√™ v√† ph√¢n t√≠ch d·ªØ li·ªáu"
      ],
      "metadata": {
        "id": "statistics_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Th·ªëng k√™ v√† ph√¢n t√≠ch d·ªØ li·ªáu\n",
        "print(\"üìä 6. TH·ªêNG K√ä V√Ä PH√ÇN T√çCH D·ªÆ LI·ªÜU\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "# Th·ªëng k√™ c∆° b·∫£n\n",
        "print(\"üî∏ Th·ªëng k√™ c∆° b·∫£n:\")\n",
        "print(f\"L∆∞∆°ng trung b√¨nh: {df['L∆∞∆°ng'].mean():.2f}\")\n",
        "print(f\"L∆∞∆°ng trung v·ªã: {df['L∆∞∆°ng'].median():.2f}\")\n",
        "print(f\"ƒê·ªô l·ªách chu·∫©n l∆∞∆°ng: {df['L∆∞∆°ng'].std():.2f}\")\n",
        "print(f\"L∆∞∆°ng min: {df['L∆∞∆°ng'].min()}\")\n",
        "print(f\"L∆∞∆°ng max: {df['L∆∞∆°ng'].max()}\")\n",
        "print(f\"T·ªïng l∆∞∆°ng: {df['L∆∞∆°ng'].sum():,}\")\n",
        "\n",
        "print(f\"\\nTu·ªïi th·ªëng k√™:\")\n",
        "print(f\"Tu·ªïi TB: {df['Tu·ªïi'].mean():.1f}\")\n",
        "print(f\"Tu·ªïi min: {df['Tu·ªïi'].min()}\")\n",
        "print(f\"Tu·ªïi max: {df['Tu·ªïi'].max()}\")\n",
        "\n",
        "# Quartiles v√† percentiles\n",
        "print(f\"\\nüî∏ Quartiles v√† percentiles:\")\n",
        "print(f\"Q1 (25%): {df['L∆∞∆°ng'].quantile(0.25)}\")\n",
        "print(f\"Q2 (50% - Median): {df['L∆∞∆°ng'].quantile(0.5)}\")\n",
        "print(f\"Q3 (75%): {df['L∆∞∆°ng'].quantile(0.75)}\")\n",
        "print(f\"90th percentile: {df['L∆∞∆°ng'].quantile(0.9)}\")\n",
        "\n",
        "# Value counts\n",
        "print(\"\\nüî∏ ƒê·∫øm t·∫ßn su·∫•t:\")\n",
        "print(\"Ph√¢n b·ªë theo th√†nh ph·ªë:\")\n",
        "city_counts = df['Th√†nh ph·ªë'].value_counts()\n",
        "print(city_counts)\n",
        "\n",
        "print(\"\\nPh√¢n b·ªë theo ƒë·ªô tu·ªïi:\")\n",
        "age_counts = df['Tu·ªïi'].value_counts().sort_index()\n",
        "print(age_counts)\n",
        "\n",
        "print(\"\\nPh√¢n b·ªë theo kinh nghi·ªám:\")\n",
        "exp_counts = df['Kinh nghi·ªám'].value_counts().sort_index()\n",
        "print(exp_counts)\n",
        "\n",
        "# Normalize value counts (percentage)\n",
        "print(\"\\nüî∏ Ph·∫ßn trƒÉm ph√¢n b·ªë:\")\n",
        "city_percent = df['Th√†nh ph·ªë'].value_counts(normalize=True) * 100\n",
        "print(\"Ph·∫ßn trƒÉm theo th√†nh ph·ªë:\")\n",
        "print(city_percent.round(2))"
      ],
      "metadata": {
        "id": "basic_statistics"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group By operations\n",
        "print(\"üî∏ Group By operations:\")\n",
        "\n",
        "# Group by single column\n",
        "print(\"Th·ªëng k√™ theo th√†nh ph·ªë:\")\n",
        "city_stats = df.groupby('Th√†nh ph·ªë').agg({\n",
        "    'L∆∞∆°ng': ['mean', 'max', 'min', 'count'],\n",
        "    'Tu·ªïi': 'mean',\n",
        "    'Kinh nghi·ªám': ['mean', 'max']\n",
        "})\n",
        "print(city_stats)\n",
        "\n",
        "# Flatten column names\n",
        "city_stats.columns = ['_'.join(col).strip() for col in city_stats.columns]\n",
        "print(\"\\nC√πng d·ªØ li·ªáu v·ªõi column names ƒë∆°n gi·∫£n:\")\n",
        "print(city_stats)\n",
        "\n",
        "# Group by v·ªõi ƒëi·ªÅu ki·ªán\n",
        "print(\"\\nüî∏ Group by v·ªõi ƒëi·ªÅu ki·ªán:\")\n",
        "df['Age_Group'] = df['Tu·ªïi'].apply(lambda x: 'Young' if x < 30 else 'Senior')\n",
        "age_group_stats = df.groupby('Age_Group').agg({\n",
        "    'L∆∞∆°ng': ['mean', 'count'],\n",
        "    'Kinh nghi·ªám': 'mean'\n",
        "})\n",
        "print(\"Th·ªëng k√™ theo nh√≥m tu·ªïi:\")\n",
        "print(age_group_stats)\n",
        "\n",
        "# Multiple groupby\n",
        "print(\"\\nüî∏ Multiple Group By:\")\n",
        "multi_group = df.groupby(['Th√†nh ph·ªë', 'Age_Group'])['L∆∞∆°ng'].agg(['mean', 'count'])\n",
        "print(\"Th·ªëng k√™ theo th√†nh ph·ªë v√† nh√≥m tu·ªïi:\")\n",
        "print(multi_group)\n",
        "\n",
        "# Custom aggregation function\n",
        "print(\"\\nüî∏ Custom aggregation:\")\n",
        "def salary_range(series):\n",
        "    return series.max() - series.min()\n",
        "\n",
        "custom_agg = df.groupby('Th√†nh ph·ªë')['L∆∞∆°ng'].agg([\n",
        "    ('Avg_Salary', 'mean'),\n",
        "    ('Salary_Range', salary_range),\n",
        "    ('Total_Employees', 'count')\n",
        "])\n",
        "print(\"Custom aggregation:\")\n",
        "print(custom_agg)"
      ],
      "metadata": {
        "id": "groupby_operations"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation analysis\n",
        "print(\"üî∏ Correlation analysis:\")\n",
        "print(\"Ma tr·∫≠n t∆∞∆°ng quan gi·ªØa c√°c bi·∫øn s·ªë:\")\n",
        "correlation_matrix = df[['Tu·ªïi', 'L∆∞∆°ng', 'Kinh nghi·ªám']].corr()\n",
        "print(correlation_matrix)\n",
        "\n",
        "print(\"\\nT∆∞∆°ng quan m·∫°nh nh·∫•t:\")\n",
        "# T√¨m correlation cao nh·∫•t (kh√¥ng t√≠nh diagonal)\n",
        "corr_values = correlation_matrix.values\n",
        "np.fill_diagonal(corr_values, 0)  # Set diagonal to 0\n",
        "max_corr_idx = np.unravel_index(np.argmax(np.abs(corr_values)), corr_values.shape)\n",
        "cols = correlation_matrix.columns\n",
        "print(f\"T∆∞∆°ng quan cao nh·∫•t: {cols[max_corr_idx[0]]} vs {cols[max_corr_idx[1]]} = {corr_values[max_corr_idx]:.3f}\")\n",
        "\n",
        "# Pivot table\n",
        "print(\"\\nüî∏ Pivot Table:\")\n",
        "pivot = df.pivot_table(\n",
        "    values='L∆∞∆°ng',\n",
        "    index='Th√†nh ph·ªë',\n",
        "    columns='Age_Group',\n",
        "    aggfunc=['mean', 'count'],\n",
        "    fill_value=0\n",
        ")\n",
        "print(\"Pivot table - L∆∞∆°ng theo th√†nh ph·ªë v√† nh√≥m tu·ªïi:\")\n",
        "print(pivot)\n",
        "\n",
        "# Cross tabulation\n",
        "print(\"\\nüî∏ Cross Tabulation:\")\n",
        "crosstab = pd.crosstab(df['Th√†nh ph·ªë'], df['Age_Group'], margins=True)\n",
        "print(\"Cross tabulation - S·ªë l∆∞·ª£ng nh√¢n vi√™n:\")\n",
        "print(crosstab)\n",
        "\n",
        "# Percentage cross tabulation\n",
        "crosstab_pct = pd.crosstab(df['Th√†nh ph·ªë'], df['Age_Group'], normalize='index') * 100\n",
        "print(\"\\nCross tabulation (percentage by city):\")\n",
        "print(crosstab_pct.round(2))"
      ],
      "metadata": {
        "id": "advanced_analysis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# üéØ **PH·∫¶N 3: B√ÄI T·∫¨P TH·ª∞C H√ÄNH**\n",
        "\n",
        "## B√†i t·∫≠p t·ªïng h·ª£p ki·∫øn th·ª©c NumPy v√† Pandas"
      ],
      "metadata": {
        "id": "exercises_header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üî¢ **B√ÄI T·∫¨P NUMPY**"
      ],
      "metadata": {
        "id": "numpy_exercises_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# B√†i t·∫≠p NumPy\n",
        "print(\"üî¢ B√ÄI T·∫¨P NUMPY\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "print(\"\\nüìù B√†i t·∫≠p 1: T·∫°o v√† thao t√°c m·∫£ng c∆° b·∫£n\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# T·∫°o m·∫£ng 2D t·ª´ 1 ƒë·∫øn 20, reshape th√†nh 4x5\n",
        "matrix = np.arange(1, 21).reshape(4, 5)\n",
        "print(f\"Ma tr·∫≠n 4x5:\")\n",
        "print(matrix)\n",
        "\n",
        "# T√≠nh t·ªïng t·ª´ng h√†ng v√† t·ª´ng c·ªôt\n",
        "row_sums = np.sum(matrix, axis=1)\n",
        "col_sums = np.sum(matrix, axis=0)\n",
        "print(f\"\\nT·ªïng t·ª´ng h√†ng: {row_sums}\")\n",
        "print(f\"T·ªïng t·ª´ng c·ªôt: {col_sums}\")\n",
        "\n",
        "# T√¨m gi√° tr·ªã l·ªõn nh·∫•t v√† nh·ªè nh·∫•t\n",
        "print(f\"\\nGi√° tr·ªã l·ªõn nh·∫•t: {np.max(matrix)}\")\n",
        "print(f\"Gi√° tr·ªã nh·ªè nh·∫•t: {np.min(matrix)}\")\n",
        "print(f\"V·ªã tr√≠ max: {np.unravel_index(np.argmax(matrix), matrix.shape)}\")\n",
        "print(f\"V·ªã tr√≠ min: {np.unravel_index(np.argmin(matrix), matrix.shape)}\")\n",
        "\n",
        "# T√≠nh trung b√¨nh\n",
        "print(f\"\\nTrung b√¨nh to√†n b·ªô: {np.mean(matrix):.2f}\")\n",
        "print(f\"Trung b√¨nh t·ª´ng h√†ng: {np.mean(matrix, axis=1)}\")\n",
        "print(f\"Trung b√¨nh t·ª´ng c·ªôt: {np.mean(matrix, axis=0)}\")\n",
        "\n",
        "print(\"\\nüìù B√†i t·∫≠p 2: Broadcasting v√† ph√©p to√°n\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# T·∫°o m·∫£ng v√† vector\n",
        "A = np.random.randint(1, 10, (3, 4))\n",
        "v = np.array([1, 2, 3, 4])\n",
        "\n",
        "print(f\"Ma tr·∫≠n A (3x4):\")\n",
        "print(A)\n",
        "print(f\"\\nVector v: {v}\")\n",
        "\n",
        "# Broadcasting operations\n",
        "print(f\"\\nA + v (broadcasting):\")\n",
        "print(A + v)\n",
        "\n",
        "print(f\"\\nA * v (broadcasting):\")\n",
        "print(A * v)\n",
        "\n",
        "# Normalize rows (chia m·ªói h√†ng cho t·ªïng c·ªßa n√≥)\n",
        "row_sums = np.sum(A, axis=1, keepdims=True)\n",
        "normalized = A / row_sums\n",
        "print(f\"\\nNormalized rows (sum=1):\")\n",
        "print(normalized)\n",
        "print(f\"\\nKi·ªÉm tra t·ªïng t·ª´ng h√†ng: {np.sum(normalized, axis=1)}\")"
      ],
      "metadata": {
        "id": "numpy_exercises"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüìù B√†i t·∫≠p 3: Dot product th·ª±c t·∫ø\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Scenario: Portfolio investment\n",
        "print(\"üè¶ Scenario: T√≠nh to√°n portfolio ƒë·∫ßu t∆∞\")\n",
        "\n",
        "# Stock prices v√† quantities\n",
        "stocks = ['AAPL', 'GOOGL', 'MSFT', 'TSLA', 'AMZN']\n",
        "prices = np.array([150, 2500, 300, 800, 3200])  # Gi√° c·ªï phi·∫øu\n",
        "quantities = np.array([10, 2, 5, 3, 1])         # S·ªë l∆∞·ª£ng s·ªü h·ªØu\n",
        "\n",
        "print(f\"Stocks: {stocks}\")\n",
        "print(f\"Prices: {prices}\")\n",
        "print(f\"Quantities: {quantities}\")\n",
        "\n",
        "# T·ªïng gi√° tr·ªã portfolio\n",
        "total_value = np.dot(prices, quantities)\n",
        "print(f\"\\nüí∞ T·ªïng gi√° tr·ªã portfolio: ${total_value:,}\")\n",
        "\n",
        "# Weight c·ªßa m·ªói stock\n",
        "weights = (prices * quantities) / total_value\n",
        "print(f\"\\nüìä T·ª∑ tr·ªçng t·ª´ng c·ªï phi·∫øu:\")\n",
        "for stock, weight in zip(stocks, weights):\n",
        "    print(f\"  {stock}: {weight:.2%}\")\n",
        "\n",
        "# Gi·∫£ s·ª≠ gi√° thay ƒë·ªïi +5%, -3%, +2%, +10%, -1%\n",
        "price_changes = np.array([0.05, -0.03, 0.02, 0.10, -0.01])\n",
        "new_prices = prices * (1 + price_changes)\n",
        "new_value = np.dot(new_prices, quantities)\n",
        "\n",
        "print(f\"\\nüìà Sau khi gi√° thay ƒë·ªïi:\")\n",
        "print(f\"New prices: {new_prices}\")\n",
        "print(f\"New portfolio value: ${new_value:,}\")\n",
        "print(f\"Change: ${new_value - total_value:,.2f} ({((new_value - total_value)/total_value):.2%})\")\n",
        "\n",
        "print(\"\\nüìù B√†i t·∫≠p 4: Matrix operations\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Transformation matrix\n",
        "print(\"üîÑ Linear transformation\")\n",
        "\n",
        "# Points to transform\n",
        "points = np.array([[1, 2], [3, 4], [5, 6]])  # 3 points in 2D\n",
        "print(f\"Original points:\")\n",
        "print(points)\n",
        "\n",
        "# Rotation matrix (45 degrees)\n",
        "angle = np.pi / 4  # 45 degrees in radians\n",
        "rotation_matrix = np.array([\n",
        "    [np.cos(angle), -np.sin(angle)],\n",
        "    [np.sin(angle), np.cos(angle)]\n",
        "])\n",
        "\n",
        "print(f\"\\nRotation matrix (45¬∞):\")\n",
        "print(rotation_matrix)\n",
        "\n",
        "# Apply transformation\n",
        "transformed_points = points @ rotation_matrix.T\n",
        "print(f\"\\nTransformed points:\")\n",
        "print(transformed_points)\n",
        "\n",
        "# Scaling matrix\n",
        "scale_matrix = np.array([[2, 0], [0, 3]])  # Scale x by 2, y by 3\n",
        "scaled_points = points @ scale_matrix.T\n",
        "print(f\"\\nScaled points (2x, 3y):\")\n",
        "print(scaled_points)"
      ],
      "metadata": {
        "id": "numpy_advanced_exercises"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üêº **B√ÄI T·∫¨P PANDAS**"
      ],
      "metadata": {
        "id": "pandas_exercises_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# B√†i t·∫≠p Pandas\n",
        "print(\"üêº B√ÄI T·∫¨P PANDAS\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "print(\"\\nüìù B√†i t·∫≠p 1: Ph√¢n t√≠ch d·ªØ li·ªáu sinh vi√™n\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# T·∫°o dataset sinh vi√™n\n",
        "np.random.seed(42)\n",
        "n_students = 100\n",
        "\n",
        "students_data = {\n",
        "    'StudentID': [f'ST{i+1:03d}' for i in range(n_students)],\n",
        "    'Name': [f'Student_{i+1}' for i in range(n_students)],\n",
        "    'Math': np.random.normal(75, 15, n_students).clip(0, 100),\n",
        "    'Physics': np.random.normal(70, 12, n_students).clip(0, 100),\n",
        "    'Chemistry': np.random.normal(72, 14, n_students).clip(0, 100),\n",
        "    'English': np.random.normal(78, 10, n_students).clip(0, 100),\n",
        "    'Class': np.random.choice(['A', 'B', 'C', 'D'], n_students),\n",
        "    'Gender': np.random.choice(['Male', 'Female'], n_students),\n",
        "    'Age': np.random.randint(18, 23, n_students)\n",
        "}\n",
        "\n",
        "df_students = pd.DataFrame(students_data)\n",
        "\n",
        "# L√†m tr√≤n ƒëi·ªÉm s·ªë\n",
        "df_students[['Math', 'Physics', 'Chemistry', 'English']] = df_students[['Math', 'Physics', 'Chemistry', 'English']].round(1)\n",
        "\n",
        "print(\"Dataset sinh vi√™n (10 d√≤ng ƒë·∫ßu):\")\n",
        "print(df_students.head(10))\n",
        "\n",
        "print(f\"\\nüìä Th√¥ng tin c∆° b·∫£n:\")\n",
        "print(f\"T·ªïng s·ªë sinh vi√™n: {len(df_students)}\")\n",
        "print(f\"S·ªë l·ªõp: {df_students['Class'].nunique()}\")\n",
        "print(f\"Ph√¢n b·ªë gi·ªõi t√≠nh:\\n{df_students['Gender'].value_counts()}\")\n",
        "print(f\"ƒê·ªô tu·ªïi: {df_students['Age'].min()}-{df_students['Age'].max()}\")"
      ],
      "metadata": {
        "id": "pandas_student_dataset"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ph√¢n t√≠ch d·ªØ li·ªáu sinh vi√™n\n",
        "print(\"\\nüî∏ T√≠nh ƒëi·ªÉm trung b√¨nh v√† x·∫øp lo·∫°i:\")\n",
        "\n",
        "# T√≠nh ƒëi·ªÉm trung b√¨nh\n",
        "subject_columns = ['Math', 'Physics', 'Chemistry', 'English']\n",
        "df_students['Average'] = df_students[subject_columns].mean(axis=1)\n",
        "\n",
        "# T·∫°o c·ªôt x·∫øp lo·∫°i\n",
        "def classify_grade(avg):\n",
        "    if avg >= 85:\n",
        "        return 'Excellent'\n",
        "    elif avg >= 75:\n",
        "        return 'Good'\n",
        "    elif avg >= 65:\n",
        "        return 'Average'\n",
        "    elif avg >= 50:\n",
        "        return 'Below Average'\n",
        "    else:\n",
        "        return 'Poor'\n",
        "\n",
        "df_students['Grade'] = df_students['Average'].apply(classify_grade)\n",
        "\n",
        "print(\"Top 10 sinh vi√™n c√≥ ƒëi·ªÉm TB cao nh·∫•t:\")\n",
        "top_students = df_students.nlargest(10, 'Average')[['Name', 'Class', 'Average', 'Grade']]\n",
        "print(top_students)\n",
        "\n",
        "print(\"\\nüî∏ Ph√¢n b·ªë x·∫øp lo·∫°i:\")\n",
        "grade_distribution = df_students['Grade'].value_counts()\n",
        "print(grade_distribution)\n",
        "print(\"\\nPh·∫ßn trƒÉm:\")\n",
        "print((grade_distribution / len(df_students) * 100).round(2))\n",
        "\n",
        "print(\"\\nüî∏ Th·ªëng k√™ theo l·ªõp:\")\n",
        "class_stats = df_students.groupby('Class').agg({\n",
        "    'Average': ['mean', 'max', 'min', 'std'],\n",
        "    'Name': 'count'\n",
        "}).round(2)\n",
        "class_stats.columns = ['Avg_Score', 'Max_Score', 'Min_Score', 'Std_Score', 'Student_Count']\n",
        "print(class_stats)\n",
        "\n",
        "print(\"\\nüî∏ Th·ªëng k√™ theo gi·ªõi t√≠nh:\")\n",
        "gender_stats = df_students.groupby('Gender')[subject_columns + ['Average']].mean().round(2)\n",
        "print(gender_stats)\n",
        "\n",
        "print(\"\\nüî∏ T∆∞∆°ng quan gi·ªØa c√°c m√¥n h·ªçc:\")\n",
        "subject_correlation = df_students[subject_columns].corr().round(3)\n",
        "print(subject_correlation)"
      ],
      "metadata": {
        "id": "student_analysis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüìù B√†i t·∫≠p 2: Ph√¢n t√≠ch d·ªØ li·ªáu b√°n h√†ng\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# T·∫°o dataset b√°n h√†ng\n",
        "np.random.seed(123)\n",
        "n_transactions = 1000\n",
        "\n",
        "# T·∫°o date range\n",
        "date_range = pd.date_range('2024-01-01', '2024-12-31', freq='D')\n",
        "products = ['Laptop', 'Phone', 'Tablet', 'Watch', 'Headphones', 'Speaker', 'Camera']\n",
        "regions = ['North', 'South', 'East', 'West', 'Central']\n",
        "salespersons = [f'Sales_{i+1}' for i in range(20)]\n",
        "\n",
        "sales_data = {\n",
        "    'TransactionID': [f'T{i+1:04d}' for i in range(n_transactions)],\n",
        "    'Date': np.random.choice(date_range, n_transactions),\n",
        "    'Product': np.random.choice(products, n_transactions),\n",
        "    'Quantity': np.random.randint(1, 5, n_transactions),\n",
        "    'Unit_Price': np.random.uniform(100, 1500, n_transactions).round(2),\n",
        "    'Region': np.random.choice(regions, n_transactions),\n",
        "    'Salesperson': np.random.choice(salespersons, n_transactions),\n",
        "    'Customer_Type': np.random.choice(['New', 'Returning'], n_transactions, p=[0.3, 0.7])\n",
        "}\n",
        "\n",
        "df_sales = pd.DataFrame(sales_data)\n",
        "\n",
        "# T√≠nh revenue\n",
        "df_sales['Revenue'] = df_sales['Quantity'] * df_sales['Unit_Price']\n",
        "\n",
        "# Extract time features\n",
        "df_sales['Year'] = df_sales['Date'].dt.year\n",
        "df_sales['Month'] = df_sales['Date'].dt.month\n",
        "df_sales['Quarter'] = df_sales['Date'].dt.quarter\n",
        "df_sales['Day_of_Week'] = df_sales['Date'].dt.day_name()\n",
        "\n",
        "print(\"Dataset b√°n h√†ng (10 d√≤ng ƒë·∫ßu):\")\n",
        "print(df_sales.head(10))\n",
        "\n",
        "print(f\"\\nüìä T·ªïng quan:\")\n",
        "print(f\"T·ªïng s·ªë giao d·ªãch: {len(df_sales):,}\")\n",
        "print(f\"T·ªïng doanh thu: ${df_sales['Revenue'].sum():,.2f}\")\n",
        "print(f\"Doanh thu trung b√¨nh/giao d·ªãch: ${df_sales['Revenue'].mean():.2f}\")\n",
        "print(f\"Giao d·ªãch l·ªõn nh·∫•t: ${df_sales['Revenue'].max():,.2f}\")\n",
        "print(f\"S·ªë s·∫£n ph·∫©m: {df_sales['Product'].nunique()}\")\n",
        "print(f\"S·ªë v√πng: {df_sales['Region'].nunique()}\")\n",
        "print(f\"S·ªë nh√¢n vi√™n b√°n h√†ng: {df_sales['Salesperson'].nunique()}\")"
      ],
      "metadata": {
        "id": "sales_dataset"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ph√¢n t√≠ch b√°n h√†ng chi ti·∫øt\n",
        "print(\"\\nüî∏ Ph√¢n t√≠ch theo s·∫£n ph·∫©m:\")\n",
        "product_analysis = df_sales.groupby('Product').agg({\n",
        "    'Revenue': ['sum', 'mean', 'count'],\n",
        "    'Quantity': 'sum',\n",
        "    'Unit_Price': 'mean'\n",
        "}).round(2)\n",
        "\n",
        "product_analysis.columns = ['Total_Revenue', 'Avg_Revenue', 'Transaction_Count', 'Total_Quantity', 'Avg_Price']\n",
        "product_analysis = product_analysis.sort_values('Total_Revenue', ascending=False)\n",
        "print(product_analysis)\n",
        "\n",
        "print(\"\\nüî∏ Ph√¢n t√≠ch theo v√πng:\")\n",
        "region_analysis = df_sales.groupby('Region').agg({\n",
        "    'Revenue': ['sum', 'mean'],\n",
        "    'TransactionID': 'count'\n",
        "}).round(2)\n",
        "region_analysis.columns = ['Total_Revenue', 'Avg_Revenue', 'Transaction_Count']\n",
        "region_analysis['Revenue_Share'] = (region_analysis['Total_Revenue'] / region_analysis['Total_Revenue'].sum() * 100).round(2)\n",
        "print(region_analysis.sort_values('Total_Revenue', ascending=False))\n",
        "\n",
        "print(\"\\nüî∏ Ph√¢n t√≠ch theo th√°ng:\")\n",
        "monthly_analysis = df_sales.groupby('Month').agg({\n",
        "    'Revenue': 'sum',\n",
        "    'TransactionID': 'count'\n",
        "}).round(2)\n",
        "monthly_analysis.columns = ['Total_Revenue', 'Transaction_Count']\n",
        "monthly_analysis['Avg_Revenue_per_Transaction'] = (monthly_analysis['Total_Revenue'] / monthly_analysis['Transaction_Count']).round(2)\n",
        "print(monthly_analysis)\n",
        "\n",
        "print(\"\\nüî∏ Top 10 nh√¢n vi√™n b√°n h√†ng:\")\n",
        "top_salespeople = df_sales.groupby('Salesperson').agg({\n",
        "    'Revenue': 'sum',\n",
        "    'TransactionID': 'count'\n",
        "}).round(2)\n",
        "top_salespeople.columns = ['Total_Revenue', 'Transaction_Count']\n",
        "top_salespeople['Avg_Revenue_per_Transaction'] = (top_salespeople['Total_Revenue'] / top_salespeople['Transaction_Count']).round(2)\n",
        "top_salespeople = top_salespeople.sort_values('Total_Revenue', ascending=False).head(10)\n",
        "print(top_salespeople)\n",
        "\n",
        "print(\"\\nüî∏ Ph√¢n t√≠ch theo lo·∫°i kh√°ch h√†ng:\")\n",
        "customer_analysis = df_sales.groupby('Customer_Type').agg({\n",
        "    'Revenue': ['sum', 'mean', 'count']\n",
        "}).round(2)\n",
        "customer_analysis.columns = ['Total_Revenue', 'Avg_Revenue', 'Transaction_Count']\n",
        "print(customer_analysis)\n",
        "\n",
        "print(\"\\nüî∏ Ph√¢n t√≠ch theo ng√†y trong tu·∫ßn:\")\n",
        "day_analysis = df_sales.groupby('Day_of_Week').agg({\n",
        "    'Revenue': ['sum', 'mean'],\n",
        "    'TransactionID': 'count'\n",
        "}).round(2)\n",
        "day_analysis.columns = ['Total_Revenue', 'Avg_Revenue', 'Transaction_Count']\n",
        "# Reorder by day of week\n",
        "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "day_analysis = day_analysis.reindex(day_order)\n",
        "print(day_analysis)"
      ],
      "metadata": {
        "id": "sales_analysis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# üéâ **K·∫æT LU·∫¨N V√Ä B∆Ø·ªöC TI·∫æP THEO**\n",
        "\n",
        "## üìö **T√≥m t·∫Øt ki·∫øn th·ª©c ƒë√£ h·ªçc:**\n",
        "\n",
        "### **NumPy:**\n",
        "- ‚úÖ T·∫°o v√† thao t√°c m·∫£ng ƒëa chi·ªÅu\n",
        "- ‚úÖ Indexing, slicing, broadcasting\n",
        "- ‚úÖ C√°c ph√©p to√°n to√°n h·ªçc v√† th·ªëng k√™\n",
        "- ‚úÖ Dot product v√† linear algebra\n",
        "- ‚úÖ Random number generation\n",
        "\n",
        "### **Pandas:**\n",
        "- ‚úÖ Series v√† DataFrame\n",
        "- ‚úÖ ƒê·ªçc, ghi, v√† thao t√°c d·ªØ li·ªáu\n",
        "- ‚úÖ L·ªçc v√† t√¨m ki·∫øm d·ªØ li·ªáu\n",
        "- ‚úÖ X·ª≠ l√Ω d·ªØ li·ªáu thi·∫øu\n",
        "- ‚úÖ Group by v√† aggregation\n",
        "- ‚úÖ Th·ªëng k√™ v√† ph√¢n t√≠ch d·ªØ li·ªáu\n",
        "\n",
        "## üöÄ **B∆∞·ªõc ti·∫øp theo:**\n",
        "1. **Matplotlib/Seaborn** - Visualization\n",
        "2. **Scikit-learn** - Machine Learning\n",
        "3. **Jupyter Notebook** - Interactive analysis\n",
        "4. **Real projects** - √Åp d·ª•ng v√†o d·ª± √°n th·ª±c t·∫ø\n",
        "\n",
        "## üí° **Tips ƒë·ªÉ th√†nh th·∫°o:**\n",
        "- Th·ª±c h√†nh h√†ng ng√†y v·ªõi dataset th·∫≠t\n",
        "- Tham gia c√°c competition tr√™n Kaggle\n",
        "- ƒê·ªçc documentation v√† examples\n",
        "- Build portfolio projects\n",
        "\n",
        "---\n",
        "**üéì Ch√∫c b·∫°n h·ªçc t·∫≠p hi·ªáu qu·∫£ v√† th√†nh c√¥ng v·ªõi Data Science!**"
      ],
      "metadata": {
        "id": "conclusion"
      }
    }
  ]
}